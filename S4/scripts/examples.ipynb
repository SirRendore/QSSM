{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..')) # Add parent directory to path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Pykeops installation found.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from utils import read_yaml\n",
    "from parse_arguments import ConfigParser\n",
    "from train import set_up_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r'/home/leo/QuantisedSSM/S4/configs/S4D_small.yaml'\n",
    "# resume_checkpoint = r\"/home/leo/QuantisedSSM/S4/log/S4D_small/fp32_16heads/checkpoint/ckpt.pth\"\n",
    "resume_checkpoint = None\n",
    "\n",
    "config_yaml = read_yaml(fname)\n",
    "# modification = {\"model;type\": 32}\n",
    "modification = None\n",
    "config = ConfigParser(config_yaml, resume_checkpoint, modification=modification, save_log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 16]             32\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 16, 784]             --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 16]             3,104\n",
      "|    |    └─Identity: 3-2                [-1, 784, 16]             --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 16]             --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 16]             544\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 16, 784]             --\n",
      "├─Linear: 1-2                            [-1, 10]                  170\n",
      "==========================================================================================\n",
      "Total params: 3,850\n",
      "Trainable params: 3,850\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.40\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "trainer = set_up_trainer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 1.534 | Acc: 59.606% (29803/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.254 | Acc: 92.600% (9260/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.241 | Acc: 92.790% (9279/10000): : 20it [00:02,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Acc: 59.606, Val Acc: 92.6, Test Acc: 92.79, LR: [0.009938441702975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.179 | Acc: 94.764% (47382/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.112 | Acc: 96.770% (9677/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.106 | Acc: 96.750% (9675/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Acc: 94.764, Val Acc: 96.77, Test Acc: 96.75, LR: [0.009755282581475769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.105 | Acc: 96.758% (48379/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.091 | Acc: 97.140% (9714/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.082 | Acc: 97.440% (9744/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Acc: 96.758, Val Acc: 97.14, Test Acc: 97.44, LR: [0.00945503262094184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.081 | Acc: 97.426% (48713/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.071 | Acc: 97.750% (9775/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.063 | Acc: 98.080% (9808/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Acc: 97.426, Val Acc: 97.75, Test Acc: 98.08, LR: [0.009045084971874739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.068 | Acc: 97.926% (48963/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.073 | Acc: 97.830% (9783/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.062 | Acc: 98.070% (9807/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Acc: 97.926, Val Acc: 97.83, Test Acc: 98.07, LR: [0.008535533905932738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.056 | Acc: 98.286% (49143/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.055 | Acc: 98.350% (9835/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.048 | Acc: 98.530% (9853/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Acc: 98.286, Val Acc: 98.35, Test Acc: 98.53, LR: [0.007938926261462366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.046 | Acc: 98.524% (49262/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.056 | Acc: 98.350% (9835/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.049 | Acc: 98.570% (9857/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Acc: 98.524, Val Acc: 98.35, Test Acc: 98.57, LR: [0.007269952498697735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.042 | Acc: 98.630% (49315/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.048 | Acc: 98.350% (9835/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.040 | Acc: 98.780% (9878/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Acc: 98.63, Val Acc: 98.35, Test Acc: 98.78, LR: [0.006545084971874738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.037 | Acc: 98.850% (49425/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.066 | Acc: 97.950% (9795/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.053 | Acc: 98.250% (9825/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Acc: 98.85, Val Acc: 97.95, Test Acc: 98.25, LR: [0.005782172325201155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.034 | Acc: 98.902% (49451/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.059 | Acc: 98.060% (9806/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.052 | Acc: 98.340% (9834/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Acc: 98.902, Val Acc: 98.06, Test Acc: 98.34, LR: [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.032 | Acc: 98.964% (49482/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.640% (9864/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.990% (9899/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Acc: 98.964, Val Acc: 98.64, Test Acc: 98.99, LR: [0.004217827674798847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.025 | Acc: 99.204% (49602/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.036 | Acc: 98.800% (9880/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Acc: 99.204, Val Acc: 98.8, Test Acc: 99.06, LR: [0.0034549150281252636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.020 | Acc: 99.372% (49686/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.041 | Acc: 98.540% (9854/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.039 | Acc: 98.850% (9885/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Acc: 99.372, Val Acc: 98.54, Test Acc: 98.85, LR: [0.0027300475013022664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.019 | Acc: 99.426% (49713/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.920% (9892/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.110% (9911/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Acc: 99.426, Val Acc: 98.92, Test Acc: 99.11, LR: [0.0020610737385376348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.015 | Acc: 99.584% (49792/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 98.970% (9897/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Acc: 99.584, Val Acc: 98.97, Test Acc: 99.08, LR: [0.0014644660940672626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.013 | Acc: 99.640% (49820/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 98.970% (9897/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.029 | Acc: 99.180% (9918/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Acc: 99.64, Val Acc: 98.97, Test Acc: 99.18, LR: [0.0009549150281252633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.688% (49844/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.900% (9890/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.160% (9916/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Acc: 99.688, Val Acc: 98.9, Test Acc: 99.16, LR: [0.0005449673790581611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.760% (49880/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0207_104603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.200% (9920/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Acc: 99.76, Val Acc: 99.08, Test Acc: 99.2, LR: [0.00024471741852423234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.788% (49894/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.070% (9907/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Acc: 99.788, Val Acc: 99.07, Test Acc: 99.17, LR: [6.15582970243117e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.804% (49902/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Acc: 99.804, Val Acc: 99.06, Test Acc: 99.15, LR: [0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.808% (49904/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Acc: 99.808, Val Acc: 99.06, Test Acc: 99.15, LR: [6.155829702431115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.804% (49902/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.190% (9919/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Acc: 99.804, Val Acc: 99.06, Test Acc: 99.19, LR: [0.00024471741852423126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.790% (49895/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.050% (9905/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.160% (9916/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Acc: 99.79, Val Acc: 99.05, Test Acc: 99.16, LR: [0.0005449673790581606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.782% (49891/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.130% (9913/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Acc: 99.782, Val Acc: 98.96, Test Acc: 99.13, LR: [0.0009549150281252623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.768% (49884/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.030% (9903/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.250% (9925/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Acc: 99.768, Val Acc: 99.03, Test Acc: 99.25, LR: [0.0014644660940672616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.638% (49819/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.900% (9890/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.210% (9921/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Acc: 99.638, Val Acc: 98.9, Test Acc: 99.21, LR: [0.002061073738537634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.013 | Acc: 99.630% (49815/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.000% (9900/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.110% (9911/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Acc: 99.63, Val Acc: 99.0, Test Acc: 99.11, LR: [0.002730047501302265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.020 | Acc: 99.378% (49689/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.057 | Acc: 98.260% (9826/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.062 | Acc: 98.330% (9833/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Acc: 99.378, Val Acc: 98.26, Test Acc: 98.33, LR: [0.003454915028125262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.028 | Acc: 99.060% (49530/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.070 | Acc: 97.820% (9782/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.063 | Acc: 98.110% (9811/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Acc: 99.06, Val Acc: 97.82, Test Acc: 98.11, LR: [0.004217827674798845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.030 | Acc: 99.070% (49535/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.046 | Acc: 98.640% (9864/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Acc: 99.07, Val Acc: 98.64, Test Acc: 98.96, LR: [0.004999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 98.96, Loss: 0.03668064445373602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.03668064445373602, 'acc': 98.96}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 512]            1,024\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 512, 784]            --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 512]            99,328\n",
      "|    |    └─Identity: 3-2                [-1, 784, 512]            --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 512]            --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 512]            525,312\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 512, 784]            --\n",
      "├─Linear: 1-2                            [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 630,794\n",
      "Trainable params: 630,794\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.25\n",
      "Params size (MB): 2.41\n",
      "Estimated Total Size (MB): 14.66\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 1.534 | Acc: 59.606% (29803/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.254 | Acc: 92.600% (9260/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.241 | Acc: 92.790% (9279/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Acc: 59.606, Val Acc: 92.6, Test Acc: 92.79, LR: [0.009938441702975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.179 | Acc: 94.764% (47382/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.112 | Acc: 96.770% (9677/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.106 | Acc: 96.750% (9675/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Acc: 94.764, Val Acc: 96.77, Test Acc: 96.75, LR: [0.009755282581475769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.105 | Acc: 96.758% (48379/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.091 | Acc: 97.140% (9714/10000): : 20it [00:02,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.082 | Acc: 97.440% (9744/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Acc: 96.758, Val Acc: 97.14, Test Acc: 97.44, LR: [0.00945503262094184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.081 | Acc: 97.426% (48713/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.071 | Acc: 97.750% (9775/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.063 | Acc: 98.080% (9808/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Acc: 97.426, Val Acc: 97.75, Test Acc: 98.08, LR: [0.009045084971874739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.068 | Acc: 97.926% (48963/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.073 | Acc: 97.830% (9783/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.062 | Acc: 98.070% (9807/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Acc: 97.926, Val Acc: 97.83, Test Acc: 98.07, LR: [0.008535533905932738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.056 | Acc: 98.286% (49143/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.055 | Acc: 98.350% (9835/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.048 | Acc: 98.530% (9853/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Acc: 98.286, Val Acc: 98.35, Test Acc: 98.53, LR: [0.007938926261462366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.046 | Acc: 98.524% (49262/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.056 | Acc: 98.350% (9835/10000): : 20it [00:02,  7.74it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.049 | Acc: 98.570% (9857/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Acc: 98.524, Val Acc: 98.35, Test Acc: 98.57, LR: [0.007269952498697735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.042 | Acc: 98.630% (49315/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.048 | Acc: 98.350% (9835/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.040 | Acc: 98.780% (9878/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Acc: 98.63, Val Acc: 98.35, Test Acc: 98.78, LR: [0.006545084971874738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.037 | Acc: 98.850% (49425/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.066 | Acc: 97.950% (9795/10000): : 20it [00:02,  7.67it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.053 | Acc: 98.250% (9825/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Acc: 98.85, Val Acc: 97.95, Test Acc: 98.25, LR: [0.005782172325201155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.034 | Acc: 98.902% (49451/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.059 | Acc: 98.060% (9806/10000): : 20it [00:02,  7.57it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.052 | Acc: 98.340% (9834/10000): : 20it [00:02,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Acc: 98.902, Val Acc: 98.06, Test Acc: 98.34, LR: [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.032 | Acc: 98.964% (49482/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.640% (9864/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.990% (9899/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Acc: 98.964, Val Acc: 98.64, Test Acc: 98.99, LR: [0.004217827674798847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.025 | Acc: 99.204% (49602/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.036 | Acc: 98.800% (9880/10000): : 20it [00:02,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Acc: 99.204, Val Acc: 98.8, Test Acc: 99.06, LR: [0.0034549150281252636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.020 | Acc: 99.372% (49686/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.041 | Acc: 98.540% (9854/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.039 | Acc: 98.850% (9885/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Acc: 99.372, Val Acc: 98.54, Test Acc: 98.85, LR: [0.0027300475013022664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.019 | Acc: 99.426% (49713/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.920% (9892/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.110% (9911/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Acc: 99.426, Val Acc: 98.92, Test Acc: 99.11, LR: [0.0020610737385376348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.015 | Acc: 99.584% (49792/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 98.970% (9897/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Acc: 99.584, Val Acc: 98.97, Test Acc: 99.08, LR: [0.0014644660940672626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.013 | Acc: 99.640% (49820/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 98.970% (9897/10000): : 20it [00:02,  7.66it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.029 | Acc: 99.180% (9918/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Acc: 99.64, Val Acc: 98.97, Test Acc: 99.18, LR: [0.0009549150281252633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.688% (49844/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.900% (9890/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.160% (9916/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Acc: 99.688, Val Acc: 98.9, Test Acc: 99.16, LR: [0.0005449673790581611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.760% (49880/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_180315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.200% (9920/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Acc: 99.76, Val Acc: 99.08, Test Acc: 99.2, LR: [0.00024471741852423234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.788% (49894/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.070% (9907/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Acc: 99.788, Val Acc: 99.07, Test Acc: 99.17, LR: [6.15582970243117e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.804% (49902/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.64it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Acc: 99.804, Val Acc: 99.06, Test Acc: 99.15, LR: [0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.808% (49904/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Acc: 99.808, Val Acc: 99.06, Test Acc: 99.15, LR: [6.155829702431115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.804% (49902/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.190% (9919/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Acc: 99.804, Val Acc: 99.06, Test Acc: 99.19, LR: [0.00024471741852423126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.790% (49895/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.050% (9905/10000): : 20it [00:02,  7.67it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.160% (9916/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Acc: 99.79, Val Acc: 99.05, Test Acc: 99.16, LR: [0.0005449673790581606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.782% (49891/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.130% (9913/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Acc: 99.782, Val Acc: 98.96, Test Acc: 99.13, LR: [0.0009549150281252623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.768% (49884/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.030% (9903/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.250% (9925/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Acc: 99.768, Val Acc: 99.03, Test Acc: 99.25, LR: [0.0014644660940672616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.638% (49819/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.900% (9890/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.210% (9921/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Acc: 99.638, Val Acc: 98.9, Test Acc: 99.21, LR: [0.002061073738537634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.013 | Acc: 99.630% (49815/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.000% (9900/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.110% (9911/10000): : 20it [00:02,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Acc: 99.63, Val Acc: 99.0, Test Acc: 99.11, LR: [0.002730047501302265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.020 | Acc: 99.378% (49689/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.057 | Acc: 98.260% (9826/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.062 | Acc: 98.330% (9833/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Acc: 99.378, Val Acc: 98.26, Test Acc: 98.33, LR: [0.003454915028125262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.028 | Acc: 99.060% (49530/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.070 | Acc: 97.820% (9782/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.063 | Acc: 98.110% (9811/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Acc: 99.06, Val Acc: 97.82, Test Acc: 98.11, LR: [0.004217827674798845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.030 | Acc: 99.070% (49535/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.046 | Acc: 98.640% (9864/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Acc: 99.07, Val Acc: 98.64, Test Acc: 98.96, LR: [0.004999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 98.96, Loss: 0.03668064445373602\n",
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 512]            1,024\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 512, 784]            --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 512]            99,328\n",
      "|    |    └─Identity: 3-2                [-1, 784, 512]            --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 512]            --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 512]            525,312\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 512, 784]            --\n",
      "├─Linear: 1-2                            [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 630,794\n",
      "Trainable params: 630,794\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.25\n",
      "Params size (MB): 2.41\n",
      "Estimated Total Size (MB): 14.66\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 1.655 | Acc: 57.540% (28770/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.257 | Acc: 92.680% (9268/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.239 | Acc: 93.260% (9326/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Acc: 57.54, Val Acc: 92.68, Test Acc: 93.26, LR: [0.009938441702975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.185 | Acc: 94.692% (47346/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.126 | Acc: 96.440% (9644/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.122 | Acc: 96.470% (9647/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Acc: 94.692, Val Acc: 96.44, Test Acc: 96.47, LR: [0.009755282581475769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.110 | Acc: 96.706% (48353/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.119 | Acc: 96.040% (9604/10000): : 20it [00:02,  7.34it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.111 | Acc: 96.310% (9631/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Acc: 96.706, Val Acc: 96.04, Test Acc: 96.31, LR: [0.00945503262094184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.090 | Acc: 97.230% (48615/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.072 | Acc: 97.830% (9783/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.069 | Acc: 97.840% (9784/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Acc: 97.23, Val Acc: 97.83, Test Acc: 97.84, LR: [0.009045084971874739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.064 | Acc: 98.048% (49024/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.072 | Acc: 97.730% (9773/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.058 | Acc: 98.030% (9803/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Acc: 98.048, Val Acc: 97.73, Test Acc: 98.03, LR: [0.008535533905932738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.059 | Acc: 98.172% (49086/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.052 | Acc: 98.290% (9829/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.041 | Acc: 98.690% (9869/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Acc: 98.172, Val Acc: 98.29, Test Acc: 98.69, LR: [0.007938926261462366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.052 | Acc: 98.370% (49185/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.075 | Acc: 97.560% (9756/10000): : 20it [00:02,  7.67it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.073 | Acc: 97.830% (9783/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Acc: 98.37, Val Acc: 97.56, Test Acc: 97.83, LR: [0.007269952498697735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.044 | Acc: 98.664% (49332/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.045 | Acc: 98.590% (9859/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.920% (9892/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Acc: 98.664, Val Acc: 98.59, Test Acc: 98.92, LR: [0.006545084971874738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.037 | Acc: 98.846% (49423/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.042 | Acc: 98.740% (9874/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.830% (9883/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Acc: 98.846, Val Acc: 98.74, Test Acc: 98.83, LR: [0.005782172325201155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.033 | Acc: 98.982% (49491/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.860% (9886/10000): : 20it [00:02,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.850% (9885/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Acc: 98.982, Val Acc: 98.86, Test Acc: 98.85, LR: [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.030 | Acc: 99.008% (49504/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.040 | Acc: 98.780% (9878/10000): : 20it [00:02,  7.66it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.031 | Acc: 98.990% (9899/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Acc: 99.008, Val Acc: 98.78, Test Acc: 98.99, LR: [0.004217827674798847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.026 | Acc: 99.200% (49600/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.770% (9877/10000): : 20it [00:02,  7.67it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.034 | Acc: 98.990% (9899/10000): : 20it [00:02,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Acc: 99.2, Val Acc: 98.77, Test Acc: 98.99, LR: [0.0034549150281252636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.024 | Acc: 99.190% (49595/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.034 | Acc: 99.020% (9902/10000): : 20it [00:02,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.190% (9919/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Acc: 99.19, Val Acc: 99.02, Test Acc: 99.19, LR: [0.0027300475013022664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.019 | Acc: 99.392% (49696/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.970% (9897/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.050% (9905/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Acc: 99.392, Val Acc: 98.97, Test Acc: 99.05, LR: [0.0020610737385376348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.015 | Acc: 99.510% (49755/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.240% (9924/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Acc: 99.51, Val Acc: 99.08, Test Acc: 99.24, LR: [0.0014644660940672626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.014 | Acc: 99.594% (49797/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.970% (9897/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.300% (9930/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Acc: 99.594, Val Acc: 98.97, Test Acc: 99.3, LR: [0.0009549150281252633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.648% (49824/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.230% (9923/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_181859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Acc: 99.648, Val Acc: 99.23, Test Acc: 99.31, LR: [0.0005449673790581611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.734% (49867/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.120% (9912/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.340% (9934/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Acc: 99.734, Val Acc: 99.12, Test Acc: 99.34, LR: [0.00024471741852423234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.752% (49876/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.210% (9921/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Acc: 99.752, Val Acc: 99.21, Test Acc: 99.31, LR: [6.15582970243117e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.766% (49883/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.210% (9921/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.330% (9933/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Acc: 99.766, Val Acc: 99.21, Test Acc: 99.33, LR: [0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.786% (49893/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.210% (9921/10000): : 20it [00:02,  7.64it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.330% (9933/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Acc: 99.786, Val Acc: 99.21, Test Acc: 99.33, LR: [6.155829702431115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.776% (49888/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.210% (9921/10000): : 20it [00:02,  7.65it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Acc: 99.776, Val Acc: 99.21, Test Acc: 99.31, LR: [0.00024471741852423126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.754% (49877/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.180% (9918/10000): : 20it [00:02,  7.55it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.320% (9932/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Acc: 99.754, Val Acc: 99.18, Test Acc: 99.32, LR: [0.0005449673790581606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.740% (49870/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.120% (9912/10000): : 20it [00:02,  7.66it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.270% (9927/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Acc: 99.74, Val Acc: 99.12, Test Acc: 99.27, LR: [0.0009549150281252623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.672% (49836/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.350% (9935/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Acc: 99.672, Val Acc: 99.17, Test Acc: 99.35, LR: [0.0014644660940672616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.013 | Acc: 99.608% (49804/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.029 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.67it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.220% (9922/10000): : 20it [00:02,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Acc: 99.608, Val Acc: 99.17, Test Acc: 99.22, LR: [0.002061073738537634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.013 | Acc: 99.596% (49798/50000): : 98it [00:26,  3.72it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.810% (9881/10000): : 20it [00:02,  7.50it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Acc: 99.596, Val Acc: 98.81, Test Acc: 99.15, LR: [0.002730047501302265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.023 | Acc: 99.214% (49607/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.040 | Acc: 98.750% (9875/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.050% (9905/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Acc: 99.214, Val Acc: 98.75, Test Acc: 99.05, LR: [0.003454915028125262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.023 | Acc: 99.240% (49620/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.049 | Acc: 98.450% (9845/10000): : 20it [00:02,  7.66it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.830% (9883/10000): : 20it [00:02,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Acc: 99.24, Val Acc: 98.45, Test Acc: 98.83, LR: [0.004217827674798845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.030 | Acc: 98.982% (49491/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.049 | Acc: 98.410% (9841/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.780% (9878/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Acc: 98.982, Val Acc: 98.41, Test Acc: 98.78, LR: [0.004999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.780% (9878/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 98.78, Loss: 0.04299009497044608\n",
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 512]            1,024\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 512, 784]            --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 512]            99,328\n",
      "|    |    └─Identity: 3-2                [-1, 784, 512]            --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 512]            --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 512]            525,312\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 512, 784]            --\n",
      "├─Linear: 1-2                            [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 630,794\n",
      "Trainable params: 630,794\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.25\n",
      "Params size (MB): 2.41\n",
      "Estimated Total Size (MB): 14.66\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 1.504 | Acc: 59.878% (29939/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.255 | Acc: 92.470% (9247/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.243 | Acc: 92.710% (9271/10000): : 20it [00:02,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Acc: 59.878, Val Acc: 92.47, Test Acc: 92.71, LR: [0.009938441702975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.176 | Acc: 94.900% (47450/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.115 | Acc: 96.500% (9650/10000): : 20it [00:02,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.107 | Acc: 96.840% (9684/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Acc: 94.9, Val Acc: 96.5, Test Acc: 96.84, LR: [0.009755282581475769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.110 | Acc: 96.722% (48361/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.099 | Acc: 96.970% (9697/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.086 | Acc: 97.310% (9731/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Acc: 96.722, Val Acc: 96.97, Test Acc: 97.31, LR: [0.00945503262094184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.084 | Acc: 97.516% (48758/50000): : 98it [00:26,  3.71it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.075 | Acc: 97.660% (9766/10000): : 20it [00:02,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.063 | Acc: 98.020% (9802/10000): : 20it [00:02,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Acc: 97.516, Val Acc: 97.66, Test Acc: 98.02, LR: [0.009045084971874739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.062 | Acc: 98.130% (49065/50000): : 98it [00:26,  3.71it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.073 | Acc: 97.770% (9777/10000): : 20it [00:02,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.053 | Acc: 98.280% (9828/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Acc: 98.13, Val Acc: 97.77, Test Acc: 98.28, LR: [0.008535533905932738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.062 | Acc: 98.116% (49058/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.049 | Acc: 98.470% (9847/10000): : 20it [00:02,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.042 | Acc: 98.800% (9880/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Acc: 98.116, Val Acc: 98.47, Test Acc: 98.8, LR: [0.007938926261462366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.049 | Acc: 98.496% (49248/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.064 | Acc: 98.000% (9800/10000): : 20it [00:02,  7.64it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.056 | Acc: 98.210% (9821/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Acc: 98.496, Val Acc: 98.0, Test Acc: 98.21, LR: [0.007269952498697735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.046 | Acc: 98.500% (49250/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.041 | Acc: 98.780% (9878/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.090% (9909/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Acc: 98.5, Val Acc: 98.78, Test Acc: 99.09, LR: [0.006545084971874738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.038 | Acc: 98.818% (49409/50000): : 98it [00:26,  3.71it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.044 | Acc: 98.620% (9862/10000): : 20it [00:02,  7.50it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.820% (9882/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Acc: 98.818, Val Acc: 98.62, Test Acc: 98.82, LR: [0.005782172325201155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.033 | Acc: 98.926% (49463/50000): : 98it [00:26,  3.70it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.039 | Acc: 98.760% (9876/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.034 | Acc: 98.970% (9897/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Acc: 98.926, Val Acc: 98.76, Test Acc: 98.97, LR: [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.027 | Acc: 99.150% (49575/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.910% (9891/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.029 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Acc: 99.15, Val Acc: 98.91, Test Acc: 99.08, LR: [0.004217827674798847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.025 | Acc: 99.218% (49609/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.036 | Acc: 98.890% (9889/10000): : 20it [00:02,  7.58it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.020% (9902/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Acc: 99.218, Val Acc: 98.89, Test Acc: 99.02, LR: [0.0034549150281252636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.020 | Acc: 99.368% (49684/50000): : 98it [00:26,  3.69it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 98.980% (9898/10000): : 20it [00:02,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.140% (9914/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Acc: 99.368, Val Acc: 98.98, Test Acc: 99.14, LR: [0.0027300475013022664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.018 | Acc: 99.434% (49717/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.950% (9895/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.180% (9918/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Acc: 99.434, Val Acc: 98.95, Test Acc: 99.18, LR: [0.0020610737385376348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.015 | Acc: 99.528% (49764/50000): : 98it [00:26,  3.69it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.190% (9919/10000): : 20it [00:02,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.300% (9930/10000): : 20it [00:02,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Acc: 99.528, Val Acc: 99.19, Test Acc: 99.3, LR: [0.0014644660940672626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.620% (49810/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.200% (9920/10000): : 20it [00:02,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.350% (9935/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Acc: 99.62, Val Acc: 99.2, Test Acc: 99.35, LR: [0.0009549150281252633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.694% (49847/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.250% (9925/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.340% (9934/10000): : 20it [00:02,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Acc: 99.694, Val Acc: 99.25, Test Acc: 99.34, LR: [0.0005449673790581611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.752% (49876/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.260% (9926/10000): : 20it [00:02,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.270% (9927/10000): : 20it [00:02,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Acc: 99.752, Val Acc: 99.26, Test Acc: 99.27, LR: [0.00024471741852423234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.784% (49892/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.250% (9925/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Acc: 99.784, Val Acc: 99.25, Test Acc: 99.31, LR: [6.15582970243117e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.794% (49897/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_183444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Acc: 99.794, Val Acc: 99.28, Test Acc: 99.31, LR: [0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.008 | Acc: 99.800% (49900/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Acc: 99.8, Val Acc: 99.28, Test Acc: 99.31, LR: [6.155829702431115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.796% (49898/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.240% (9924/10000): : 20it [00:02,  7.63it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.300% (9930/10000): : 20it [00:02,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Acc: 99.796, Val Acc: 99.24, Test Acc: 99.3, LR: [0.00024471741852423126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.792% (49896/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.260% (9926/10000): : 20it [00:02,  7.65it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.022 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Acc: 99.792, Val Acc: 99.26, Test Acc: 99.31, LR: [0.0005449673790581606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.776% (49888/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.260% (9926/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Acc: 99.776, Val Acc: 99.26, Test Acc: 99.28, LR: [0.0009549150281252623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.726% (49863/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.70it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Acc: 99.726, Val Acc: 99.15, Test Acc: 99.28, LR: [0.0014644660940672616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.656% (49828/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.66it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.120% (9912/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Acc: 99.656, Val Acc: 99.17, Test Acc: 99.12, LR: [0.002061073738537634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.015 | Acc: 99.544% (49772/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.65it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Acc: 99.544, Val Acc: 98.96, Test Acc: 99.08, LR: [0.002730047501302265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.018 | Acc: 99.408% (49704/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.036 | Acc: 98.910% (9891/10000): : 20it [00:02,  7.63it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.080% (9908/10000): : 20it [00:02,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Acc: 99.408, Val Acc: 98.91, Test Acc: 99.08, LR: [0.003454915028125262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.023 | Acc: 99.244% (49622/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.070% (9907/10000): : 20it [00:02,  7.62it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.140% (9914/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Acc: 99.244, Val Acc: 99.07, Test Acc: 99.14, LR: [0.004217827674798845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.024 | Acc: 99.198% (49599/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.039 | Acc: 98.860% (9886/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.034 | Acc: 99.090% (9909/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Acc: 99.198, Val Acc: 98.86, Test Acc: 99.09, LR: [0.004999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.034 | Acc: 99.090% (9909/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 99.09, Loss: 0.03423023885115981\n",
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 512]            1,024\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 512, 784]            --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 512]            99,328\n",
      "|    |    └─Identity: 3-2                [-1, 784, 512]            --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 512]            --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 512]            525,312\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 512, 784]            --\n",
      "├─Linear: 1-2                            [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 630,794\n",
      "Trainable params: 630,794\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.25\n",
      "Params size (MB): 2.41\n",
      "Estimated Total Size (MB): 14.66\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 1.422 | Acc: 61.374% (30687/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.221 | Acc: 93.640% (9364/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.210 | Acc: 93.890% (9389/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Acc: 61.374, Val Acc: 93.64, Test Acc: 93.89, LR: [0.009938441702975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.173 | Acc: 94.796% (47398/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.128 | Acc: 95.940% (9594/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.119 | Acc: 96.350% (9635/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Acc: 94.796, Val Acc: 95.94, Test Acc: 96.35, LR: [0.009755282581475769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.105 | Acc: 96.878% (48439/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.089 | Acc: 97.230% (9723/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.077 | Acc: 97.550% (9755/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Acc: 96.878, Val Acc: 97.23, Test Acc: 97.55, LR: [0.00945503262094184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.086 | Acc: 97.358% (48679/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.078 | Acc: 97.740% (9774/10000): : 20it [00:02,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.067 | Acc: 97.890% (9789/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Acc: 97.358, Val Acc: 97.74, Test Acc: 97.89, LR: [0.009045084971874739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.065 | Acc: 98.006% (49003/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.065 | Acc: 98.080% (9808/10000): : 20it [00:02,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.058 | Acc: 98.060% (9806/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Acc: 98.006, Val Acc: 98.08, Test Acc: 98.06, LR: [0.008535533905932738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.057 | Acc: 98.188% (49094/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.070 | Acc: 97.960% (9796/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.058 | Acc: 98.230% (9823/10000): : 20it [00:02,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Acc: 98.188, Val Acc: 97.96, Test Acc: 98.23, LR: [0.007938926261462366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.051 | Acc: 98.358% (49179/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.053 | Acc: 98.400% (9840/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.044 | Acc: 98.640% (9864/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Acc: 98.358, Val Acc: 98.4, Test Acc: 98.64, LR: [0.007269952498697735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.045 | Acc: 98.500% (49250/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.052 | Acc: 98.520% (9852/10000): : 20it [00:02,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.540% (9854/10000): : 20it [00:02,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Acc: 98.5, Val Acc: 98.52, Test Acc: 98.54, LR: [0.006545084971874738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.039 | Acc: 98.804% (49402/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.050 | Acc: 98.450% (9845/10000): : 20it [00:02,  7.61it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.039 | Acc: 98.770% (9877/10000): : 20it [00:02,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Acc: 98.804, Val Acc: 98.45, Test Acc: 98.77, LR: [0.005782172325201155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.035 | Acc: 98.896% (49448/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.770% (9877/10000): : 20it [00:02,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.038 | Acc: 98.810% (9881/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Acc: 98.896, Val Acc: 98.77, Test Acc: 98.81, LR: [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.031 | Acc: 98.992% (49496/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.054 | Acc: 98.360% (9836/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.590% (9859/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Acc: 98.992, Val Acc: 98.36, Test Acc: 98.59, LR: [0.004217827674798847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.027 | Acc: 99.142% (49571/50000): : 98it [00:26,  3.72it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.050 | Acc: 98.530% (9853/10000): : 20it [00:02,  7.60it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.041 | Acc: 98.700% (9870/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Acc: 99.142, Val Acc: 98.53, Test Acc: 98.7, LR: [0.0034549150281252636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.022 | Acc: 99.322% (49661/50000): : 98it [00:26,  3.72it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.660% (9866/10000): : 20it [00:02,  7.51it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.110% (9911/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Acc: 99.322, Val Acc: 98.66, Test Acc: 99.11, LR: [0.0027300475013022664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.021 | Acc: 99.330% (49665/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.035 | Acc: 99.000% (9900/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Acc: 99.33, Val Acc: 99.0, Test Acc: 99.17, LR: [0.0020610737385376348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.016 | Acc: 99.514% (49757/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.940% (9894/10000): : 20it [00:02,  7.67it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.120% (9912/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Acc: 99.514, Val Acc: 98.94, Test Acc: 99.12, LR: [0.0014644660940672626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.014 | Acc: 99.630% (49815/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.034 | Acc: 99.100% (9910/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.180% (9918/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Acc: 99.63, Val Acc: 99.1, Test Acc: 99.18, LR: [0.0009549150281252633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.698% (49849/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.130% (9913/10000): : 20it [00:02,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.220% (9922/10000): : 20it [00:02,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Acc: 99.698, Val Acc: 99.13, Test Acc: 99.22, LR: [0.0005449673790581611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.752% (49876/50000): : 98it [00:26,  3.69it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.140% (9914/10000): : 20it [00:02,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_185031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.320% (9932/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Acc: 99.752, Val Acc: 99.14, Test Acc: 99.32, LR: [0.00024471741852423234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.762% (49881/50000): : 98it [00:26,  3.71it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.130% (9913/10000): : 20it [00:02,  7.42it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.023 | Acc: 99.330% (9933/10000): : 20it [00:02,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Acc: 99.762, Val Acc: 99.13, Test Acc: 99.33, LR: [6.15582970243117e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.782% (49891/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.140% (9914/10000): : 20it [00:02,  7.67it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.290% (9929/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Acc: 99.782, Val Acc: 99.14, Test Acc: 99.29, LR: [0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.802% (49901/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.140% (9914/10000): : 20it [00:02,  7.52it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.290% (9929/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Acc: 99.802, Val Acc: 99.14, Test Acc: 99.29, LR: [6.155829702431115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.790% (49895/50000): : 98it [00:26,  3.65it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.140% (9914/10000): : 20it [00:02,  7.48it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.310% (9931/10000): : 20it [00:02,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Acc: 99.79, Val Acc: 99.14, Test Acc: 99.31, LR: [0.00024471741852423126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.782% (49891/50000): : 98it [00:26,  3.72it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.140% (9914/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.270% (9927/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Acc: 99.782, Val Acc: 99.14, Test Acc: 99.27, LR: [0.0005449673790581606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.778% (49889/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.120% (9912/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Acc: 99.778, Val Acc: 99.12, Test Acc: 99.28, LR: [0.0009549150281252623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.720% (49860/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.120% (9912/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.250% (9925/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Acc: 99.72, Val Acc: 99.12, Test Acc: 99.25, LR: [0.0014644660940672616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.634% (49817/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Acc: 99.634, Val Acc: 99.06, Test Acc: 99.17, LR: [0.002061073738537634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.014 | Acc: 99.594% (49797/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.035 | Acc: 99.000% (9900/10000): : 20it [00:02,  7.54it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.160% (9916/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Acc: 99.594, Val Acc: 99.0, Test Acc: 99.16, LR: [0.002730047501302265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.018 | Acc: 99.408% (49704/50000): : 98it [00:26,  3.66it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.040 | Acc: 98.760% (9876/10000): : 20it [00:02,  7.53it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.032 | Acc: 98.950% (9895/10000): : 20it [00:02,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Acc: 99.408, Val Acc: 98.76, Test Acc: 98.95, LR: [0.003454915028125262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.025 | Acc: 99.180% (49590/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.038 | Acc: 98.960% (9896/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Acc: 99.18, Val Acc: 98.96, Test Acc: 99.06, LR: [0.004217827674798845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.025 | Acc: 99.198% (49599/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.053 | Acc: 98.320% (9832/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.042 | Acc: 98.680% (9868/10000): : 20it [00:02,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Acc: 99.198, Val Acc: 98.32, Test Acc: 98.68, LR: [0.004999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.042 | Acc: 98.680% (9868/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 98.68, Loss: 0.04220649825874716\n",
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 512]            1,024\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 512, 784]            --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 512]            99,328\n",
      "|    |    └─Identity: 3-2                [-1, 784, 512]            --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 512]            --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 512]            525,312\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 512, 784]            --\n",
      "├─Linear: 1-2                            [-1, 10]                  5,130\n",
      "==========================================================================================\n",
      "Total params: 630,794\n",
      "Trainable params: 630,794\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.25\n",
      "Params size (MB): 2.41\n",
      "Estimated Total Size (MB): 14.66\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 1.503 | Acc: 60.352% (30176/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.264 | Acc: 92.100% (9210/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.254 | Acc: 92.250% (9225/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Acc: 60.352, Val Acc: 92.1, Test Acc: 92.25, LR: [0.009938441702975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.165 | Acc: 95.104% (47552/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.125 | Acc: 96.460% (9646/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.107 | Acc: 96.680% (9668/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Acc: 95.104, Val Acc: 96.46, Test Acc: 96.68, LR: [0.009755282581475769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.101 | Acc: 96.868% (48434/50000): : 98it [00:26,  3.67it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.080 | Acc: 97.510% (9751/10000): : 20it [00:02,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.070 | Acc: 97.720% (9772/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Acc: 96.868, Val Acc: 97.51, Test Acc: 97.72, LR: [0.00945503262094184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.077 | Acc: 97.620% (48810/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.076 | Acc: 97.700% (9770/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.068 | Acc: 97.850% (9785/10000): : 20it [00:02,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Acc: 97.62, Val Acc: 97.7, Test Acc: 97.85, LR: [0.009045084971874739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.068 | Acc: 97.880% (48940/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.070 | Acc: 97.820% (9782/10000): : 20it [00:02,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.055 | Acc: 98.300% (9830/10000): : 20it [00:02,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Acc: 97.88, Val Acc: 97.82, Test Acc: 98.3, LR: [0.008535533905932738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.055 | Acc: 98.278% (49139/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.044 | Acc: 98.670% (9867/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.620% (9862/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Acc: 98.278, Val Acc: 98.67, Test Acc: 98.62, LR: [0.007938926261462366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.046 | Acc: 98.512% (49256/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.048 | Acc: 98.440% (9844/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.040 | Acc: 98.720% (9872/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Acc: 98.512, Val Acc: 98.44, Test Acc: 98.72, LR: [0.007269952498697735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.044 | Acc: 98.600% (49300/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.056 | Acc: 98.290% (9829/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.044 | Acc: 98.610% (9861/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Acc: 98.6, Val Acc: 98.29, Test Acc: 98.61, LR: [0.006545084971874738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.037 | Acc: 98.856% (49428/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.044 | Acc: 98.650% (9865/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.036 | Acc: 98.840% (9884/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Acc: 98.856, Val Acc: 98.65, Test Acc: 98.84, LR: [0.005782172325201155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.032 | Acc: 98.954% (49477/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.043 | Acc: 98.680% (9868/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.930% (9893/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Acc: 98.954, Val Acc: 98.68, Test Acc: 98.93, LR: [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.027 | Acc: 99.182% (49591/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.047 | Acc: 98.500% (9850/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.042 | Acc: 98.580% (9858/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Acc: 99.182, Val Acc: 98.5, Test Acc: 98.58, LR: [0.004217827674798847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.025 | Acc: 99.212% (49606/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.038 | Acc: 98.920% (9892/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.010% (9901/10000): : 20it [00:02,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Acc: 99.212, Val Acc: 98.92, Test Acc: 99.01, LR: [0.0034549150281252636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.020 | Acc: 99.360% (49680/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.035 | Acc: 98.940% (9894/10000): : 20it [00:02,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.190% (9919/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Acc: 99.36, Val Acc: 98.94, Test Acc: 99.19, LR: [0.0027300475013022664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.017 | Acc: 99.522% (49761/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.038 | Acc: 98.860% (9886/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.120% (9912/10000): : 20it [00:02,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Acc: 99.522, Val Acc: 98.86, Test Acc: 99.12, LR: [0.0020610737385376348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.015 | Acc: 99.586% (49793/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.030% (9903/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.027 | Acc: 99.160% (9916/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Acc: 99.586, Val Acc: 99.03, Test Acc: 99.16, LR: [0.0014644660940672626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.013 | Acc: 99.666% (49833/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Acc: 99.666, Val Acc: 99.06, Test Acc: 99.28, LR: [0.0009549150281252633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.011 | Acc: 99.746% (49873/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.031 | Acc: 99.090% (9909/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Acc: 99.746, Val Acc: 99.09, Test Acc: 99.28, LR: [0.0005449673790581611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.794% (49897/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.110% (9911/10000): : 20it [00:02,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.024 | Acc: 99.260% (9926/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Acc: 99.794, Val Acc: 99.11, Test Acc: 99.26, LR: [0.00024471741852423234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.826% (49913/50000): : 98it [00:26,  3.73it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.130% (9913/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.300% (9930/10000): : 20it [00:02,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Acc: 99.826, Val Acc: 99.13, Test Acc: 99.3, LR: [6.15582970243117e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.842% (49921/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/S4D_small/0403_190619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.270% (9927/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Acc: 99.842, Val Acc: 99.15, Test Acc: 99.27, LR: [0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.008 | Acc: 99.840% (49920/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.71it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.270% (9927/10000): : 20it [00:02,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Acc: 99.84, Val Acc: 99.15, Test Acc: 99.27, LR: [6.155829702431115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.008 | Acc: 99.838% (49919/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.150% (9915/10000): : 20it [00:02,  7.73it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Acc: 99.838, Val Acc: 99.15, Test Acc: 99.28, LR: [0.00024471741852423126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.818% (49909/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.130% (9913/10000): : 20it [00:02,  7.73it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.025 | Acc: 99.280% (9928/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Acc: 99.818, Val Acc: 99.13, Test Acc: 99.28, LR: [0.0005449673790581606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.009 | Acc: 99.796% (49898/50000): : 98it [00:26,  3.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.030 | Acc: 99.060% (9906/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.260% (9926/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Acc: 99.796, Val Acc: 99.06, Test Acc: 99.26, LR: [0.0009549150281252623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.010 | Acc: 99.756% (49878/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.032 | Acc: 99.100% (9910/10000): : 20it [00:02,  7.65it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.026 | Acc: 99.250% (9925/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Acc: 99.756, Val Acc: 99.1, Test Acc: 99.25, LR: [0.0014644660940672616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.012 | Acc: 99.646% (49823/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.036 | Acc: 98.950% (9895/10000): : 20it [00:02,  7.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.029 | Acc: 99.210% (9921/10000): : 20it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Acc: 99.646, Val Acc: 98.95, Test Acc: 99.21, LR: [0.002061073738537634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.014 | Acc: 99.558% (49779/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.033 | Acc: 99.130% (9913/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.028 | Acc: 99.170% (9917/10000): : 20it [00:02,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Acc: 99.558, Val Acc: 99.13, Test Acc: 99.17, LR: [0.002730047501302265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.020 | Acc: 99.344% (49672/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.049 | Acc: 98.560% (9856/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.900% (9890/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Acc: 99.344, Val Acc: 98.56, Test Acc: 98.9, LR: [0.003454915028125262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.024 | Acc: 99.192% (49596/50000): : 98it [00:26,  3.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.038 | Acc: 98.850% (9885/10000): : 20it [00:02,  7.68it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.034 | Acc: 99.040% (9904/10000): : 20it [00:02,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Acc: 99.192, Val Acc: 98.85, Test Acc: 99.04, LR: [0.004217827674798845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.030 | Acc: 98.994% (49497/50000): : 98it [00:26,  3.75it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.046 | Acc: 98.680% (9868/10000): : 20it [00:02,  7.69it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.850% (9885/10000): : 20it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Acc: 98.994, Val Acc: 98.68, Test Acc: 98.85, LR: [0.004999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.037 | Acc: 98.850% (9885/10000): : 20it [00:02,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 98.85, Loss: 0.03675868332211394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LOOP: run on multiple seeds\n",
    "\n",
    "fname = r'/home/leo/QuantisedSSM/S4/log/S4D_small/fp32_512heads/config.yaml'\n",
    "# resume_checkpoint = r\"/home/leo/QuantisedSSM/S4/log/S4D_small/fp32_16heads/checkpoint/ckpt.pth\"\n",
    "resume_checkpoint = None\n",
    "\n",
    "config_yaml = read_yaml(fname)\n",
    "\n",
    "for seed in range(5):\n",
    "    modification = {\"seed\": seed}\n",
    "    config = ConfigParser(config_yaml, resume_checkpoint, modification=modification, save_log=True)\n",
    "\n",
    "    trainer = set_up_trainer(config)\n",
    "    trainer.train()\n",
    "    trainer.eval()\n",
    "\n",
    "    del trainer, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/QuantisedSSM/S4/notebooks/../../S4/quantization/q_modules/qS4D_convolutional.py:121: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Pykeops installation found.\n",
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 16]             32\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 16, 784]             --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 16]             3,104\n",
      "|    |    └─Identity: 3-2                [-1, 784, 16]             --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 16]             --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 16]             544\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 16, 784]             --\n",
      "├─Linear: 1-2                            [-1, 10]                  170\n",
      "==========================================================================================\n",
      "Total params: 3,850\n",
      "Trainable params: 3,850\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.40\n",
      "==========================================================================================\n",
      "Loading checkpoint from:  /home/leo/QuantisedSSM/S4/log/S4D_small/fp32_16heads_seed0/checkpoint/ckpt.pth\n",
      "Replacing S4Block with S4BlockConvolutional\n",
      "[*] Quantizing 0\n",
      "Stored weight quantizer in S4BlockConvolutional\n",
      "[*] Replacing 0 with S4BlockConvolutional(\n",
      "  (layer): FFTConv(\n",
      "    (activation): GELU(approximate='none')\n",
      "    (kernel): SSMKernelDiag()\n",
      "    (drop): Identity()\n",
      "    (drop_kernel): Identity()\n",
      "  )\n",
      "  (mult_activation): Identity()\n",
      "  (drop): Identity()\n",
      "  (output_linear): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (1): GLU(dim=-1)\n",
      "  )\n",
      ")\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before 0\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=[-2], static_dims_to_reduce=[0, -1], num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to 0\n",
      "Quantized input activations of S4BlockConvolutional. Inserted functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=[-2], static_dims_to_reduce=[0, -1], num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') before S4BlockConvolutional\n",
      "Replacing Linear with QLinear\n",
      "[*] Quantizing encoder\n",
      "Quantized weights for weight\n",
      "[*] Replacing encoder with QLinear()\n",
      "[*] Quantizing 0\n",
      "Quantized weights for weight\n",
      "[*] Replacing 0 with QLinear()\n",
      "[*] Quantizing decoder\n",
      "Quantized weights for weight\n",
      "[*] Replacing decoder with QLinear()\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before encoder\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to encoder\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before 0\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to 0\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before decoder\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to decoder\n",
      "Quantized input activations of QLinear. Inserted functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') before QLinear\n",
      "Replacing GELU with QGELU\n",
      "[*] Quantizing activation\n",
      "[*] Replacing activation with QGELU()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/QuantisedSSM/S4/notebooks/../../train.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S4DModel(\n",
       "  (encoder): Sequential(\n",
       "    (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "    (1): QLinear()\n",
       "  )\n",
       "  (s4_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "      (1): S4BlockConvolutional(\n",
       "        (layer): FFTConv(\n",
       "          (activation): QGELU()\n",
       "          (kernel): SSMKernelDiag()\n",
       "          (drop): Identity()\n",
       "          (drop_kernel): Identity()\n",
       "        )\n",
       "        (mult_activation): Identity()\n",
       "        (drop): Identity()\n",
       "        (output_linear): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "            (1): QLinear()\n",
       "          )\n",
       "          (1): GLU(dim=-1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): Identity()\n",
       "  )\n",
       "  (dropouts): ModuleList(\n",
       "    (0): Dropout1d(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "    (1): QLinear()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantize import set_up_quantizers\n",
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(r\"/home/leo/QuantisedSSM/S4/log/S4D_small/fp32_16heads_seed0\")\n",
    "fname = model_path / \"config.yaml\"\n",
    "resume_checkpoint =  model_path / \"checkpoint\" / \"ckpt.pth\"\n",
    "config_yaml = read_yaml(fname)\n",
    "\n",
    "# q_config_fname = r\"/home/leo/QuantisedSSM/S4/configs/q_config.yaml\"\n",
    "q_config_fname = r\"/home/leo/QuantisedSSM/S4/configs/q_config_conv.yaml\"\n",
    "q_config_yaml = read_yaml(q_config_fname)\n",
    "q_config = ConfigParser(q_config_yaml, None, modification=None, save_log=False)\n",
    "\n",
    "modification = {\"run_name\": q_config[\"run_name\"]}\n",
    "\n",
    "resume_checkpoint =  r\"/home/leo/QuantisedSSM/S4/log/S4D_small/fp32_16heads_seed0/checkpoint/ckpt.pth\"\n",
    "config = ConfigParser(config_yaml, resume_checkpoint, modification=modification, save_log=False)\n",
    "\n",
    "q_trainer = set_up_trainer(config)\n",
    "set_up_quantizers(q_trainer, q_config)\n",
    "\n",
    "q_trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled quantization for S4BlockConvolutional\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m conv_layer\u001b[38;5;241m.\u001b[39mdisable_quantization_flag \n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# from S4.quantization.q_modules import qModules\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# qModules.S4BlockConvolutional\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m q_record_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_activation_statistics_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_trainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 20\u001b[0m, in \u001b[0;36mget_activation_statistics_dict\u001b[0;34m(q_trainer, recur_layer)\u001b[0m\n\u001b[1;32m     18\u001b[0m hook_handle \u001b[38;5;241m=\u001b[39m recur_layer\u001b[38;5;241m.\u001b[39mregister_forward_hook(record_statistics(q_record_dict))\n\u001b[1;32m     19\u001b[0m batch, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(q_trainer\u001b[38;5;241m.\u001b[39mtrainloader))\n\u001b[0;32m---> 20\u001b[0m \u001b[43mq_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m hook_handle\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_record_dict\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../S4/models/S4.py:2020\u001b[0m, in \u001b[0;36mS4DModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   2017\u001b[0m     z \u001b[38;5;241m=\u001b[39m norm(z\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;66;03m# Apply S4 block: we ignore the state input and output\u001b[39;00m\n\u001b[0;32m-> 2020\u001b[0m z, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;66;03m# Dropout on the output of the S4 block\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m z \u001b[38;5;241m=\u001b[39m dropout(z)\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m, in \u001b[0;36mrecord_statistics.<locals>.get_statistics\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m      9\u001b[0m record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_activation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m post_GELU_activation\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     10\u001b[0m record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_pre_activation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pre_GELU_activation\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 11\u001b[0m record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_states\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mall_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "conv_layer = q_trainer.model.s4_layers[0][1]\n",
    "\n",
    "# Define a forward hook for the S4BlockRecurrent module. \n",
    "# Store the input and output activations in a dictionary.\n",
    "def record_statistics(record_dict):\n",
    "    def get_statistics(module, input, output):\n",
    "        _, (inputs, post_GELU_activation, pre_GELU_activation, all_states) = output\n",
    "        record_dict[\"input_activation\"] = inputs.detach() if inputs is not None else None\n",
    "        record_dict[\"output_activation\"] = post_GELU_activation.detach() if post_GELU_activation is not None else None\n",
    "        record_dict[\"output_pre_activation\"] = pre_GELU_activation.detach() if pre_GELU_activation is not None else None\n",
    "        record_dict[\"all_states\"] = all_states.detach() if all_states is not None else None\n",
    "    \n",
    "    return get_statistics\n",
    "\n",
    "# Get activation statistics for a single batch. Can activate/deactivate quantisation before getting statistics.\n",
    "def get_activation_statistics_dict(q_trainer, recur_layer):\n",
    "    q_record_dict = {}\n",
    "    hook_handle = recur_layer.register_forward_hook(record_statistics(q_record_dict))\n",
    "    batch, labels = next(iter(q_trainer.trainloader))\n",
    "    q_trainer.model(batch.to(q_trainer.device))\n",
    "    hook_handle.remove()\n",
    "    return q_record_dict\n",
    "\n",
    "\n",
    "# conv_layer.enable_quantization()\n",
    "conv_layer.disable_quantization()\n",
    "conv_layer.disable_quantization_flag \n",
    "# from S4.quantization.q_modules import qModules\n",
    "# qModules.S4BlockConvolutional\n",
    "\n",
    "q_record_dict = get_activation_statistics_dict(q_trainer, conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.093 | Acc: 97.220% (9722/10000): : 20it [00:01, 18.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 97.22, Loss: 0.09282875079661608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.09282875079661608, 'acc': 97.22}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dynamically quantised: default\n",
    "q_trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W124 10:16:58.655094641 kineto_shim.cpp:415] Adding profiling metadata requires using torch.profiler with Kineto support (USE_KINETO=1)\n",
      "[W124 10:16:58.655114609 kineto_shim.cpp:415] Adding profiling metadata requires using torch.profiler with Kineto support (USE_KINETO=1)\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "image, label = next(iter(q_trainer.testloader))\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof:\n",
    "    q_trainer.model(image.to(q_trainer.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::sort         5.09%     190.375ms         7.27%     272.055ms     172.405us     179.002ms         4.60%     259.209ms     164.264us           0 b           0 b       1.78 Gb       1.78 Gb          1578  \n",
      "                    aten::abs         1.25%      46.701ms         2.11%      78.786ms      24.964us      32.571ms         0.84%      69.868ms      22.138us           0 b           0 b       1.18 Gb           0 b          3156  \n",
      "                    aten::mul         1.94%      72.608ms         1.94%      72.608ms      15.377us      51.683ms         1.33%      51.683ms      10.945us         192 b         192 b       1.18 Gb       1.18 Gb          4722  \n",
      "                  aten::clamp         0.90%      33.684ms         0.90%      33.822ms      14.338us      33.578ms         0.86%      39.227ms      16.629us           0 b           0 b     808.51 Mb     808.51 Mb          2359  \n",
      "                 aten::einsum         3.13%     117.096ms         7.70%     288.082ms     122.432us      57.610ms         1.48%     241.404ms     102.594us           0 b           0 b     802.38 Mb           0 b          2353  \n",
      "                  aten::empty         0.48%      17.825ms         0.48%      17.825ms       2.051us      40.394ms         1.04%      40.394ms       4.647us       6.18 Kb       6.18 Kb     615.45 Mb     615.45 Mb          8692  \n",
      "                aten::resize_         0.17%       6.236ms         0.17%       6.236ms       1.976us      11.294ms         0.29%      11.294ms       3.579us           0 b           0 b     607.17 Mb     607.17 Mb          3156  \n",
      "      FakeTensorQuantFunction         4.48%     167.496ms        64.12%        2.400s       3.034ms      59.168ms         1.52%        2.691s       3.402ms           0 b      -6.18 Kb     417.29 Mb    -823.48 Mb           791  \n",
      "                    aten::div         0.41%      15.195ms         0.41%      15.195ms       9.605us     665.135ms        17.10%     665.135ms     420.439us           0 b           0 b     417.29 Mb     417.29 Mb          1582  \n",
      "                     aten::to         0.55%      20.724ms        33.93%        1.270s     160.862us      28.290ms         0.73%        1.904s     241.265us           0 b           0 b     406.97 Mb           0 b          7893  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.743s\n",
      "Self CUDA time total: 3.889s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=10))\n",
    "\n",
    "# image, label = next(iter(q_trainer.testloader))\n",
    "# q_trainer.model(image.to(q_trainer.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calibration with 1 batches\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabled quantization for S4BlockRecurrent\n",
      "Disabling quantization for layer_activation\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabling quantization for state_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for y_recur_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for y_pre_output_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for state_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for y_recur_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for y_pre_output_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for state_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for y_recur_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for y_pre_output_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for S4BlockRecurrent\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Finished calibration\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "# results_log = q_trainer.eval()\n",
    "\n",
    "# Quantize activations statically\n",
    "q_trainer.calibrate(num_batches=1)\n",
    "# q_trainer.set_static_quantization()\n",
    "# q_trainer.set_dynamic_quantization()\n",
    "# results_log = q_trainer.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.7342],\n",
       "         [ 1.2082],\n",
       "         [-0.0606],\n",
       "         [ 5.0070],\n",
       "         [ 0.4697],\n",
       "         [-0.6930],\n",
       "         [ 6.1079],\n",
       "         [ 1.0016],\n",
       "         [ 5.0402],\n",
       "         [-0.0769],\n",
       "         [ 1.4305],\n",
       "         [ 1.6072],\n",
       "         [ 6.0985],\n",
       "         [ 3.7426],\n",
       "         [ 4.1993],\n",
       "         [ 3.8153]]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_trainer.model.s4_layers[0][0].amax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (7/391) | Loss: 20.838 | Acc: 12.207% (125/1024): : 8it [00:34,  4.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# QAT\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_log \u001b[38;5;241m=\u001b[39m \u001b[43mq_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# eval_log = q_trainer.eval()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# image, label = next(iter(q_trainer.testloader))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# q_trainer.model.encoder(image.to(q_trainer.device))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# q_trainer.model.encoder.state_dict()\u001b[39;00m\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../train.py:114\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    112\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\n\u001b[1;32m    113\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, targets)\n\u001b[0;32m--> 114\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip:\n\u001b[1;32m    116\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip)\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/QuantisedSSM/lib/python3.13/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# QAT\n",
    "train_log = q_trainer.train_epoch(1)\n",
    "eval_log = q_trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calibration with 1 batches\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabled quantization for S4BlockRecurrent\n",
      "Disabling quantization for state_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for y_recur_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for y_pre_output_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for state_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for y_recur_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for y_pre_output_quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Updated amax and amin for activation quantizer: max_min: tensor([[[3.6425],\n",
      "         [2.4511],\n",
      "         [4.2519],\n",
      "         [2.6107],\n",
      "         [2.7380],\n",
      "         [3.5426],\n",
      "         [4.8858],\n",
      "         [3.1578],\n",
      "         [3.5180],\n",
      "         [4.5683],\n",
      "         [1.4098],\n",
      "         [1.6816],\n",
      "         [4.8609],\n",
      "         [2.6162],\n",
      "         [3.3091],\n",
      "         [3.1171]]], device='cuda:0')\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for state_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Updated amax and amin for activation quantizer: max_min: tensor([[[[5.2213e-01],\n",
      "          [7.1726e-01],\n",
      "          [9.5925e-01],\n",
      "          [1.0273e+00],\n",
      "          [9.1132e-01],\n",
      "          [2.4991e-01],\n",
      "          [3.7981e-01],\n",
      "          [7.1501e-01],\n",
      "          [4.9610e-01],\n",
      "          [3.8655e-01],\n",
      "          [1.2252e-01],\n",
      "          [2.0110e-01],\n",
      "          [3.1722e-01],\n",
      "          [3.1266e-01],\n",
      "          [7.2624e-02],\n",
      "          [1.0142e-01],\n",
      "          [1.1897e-01],\n",
      "          [1.3262e-01],\n",
      "          [1.0684e-01],\n",
      "          [2.3210e-03],\n",
      "          [1.0763e-01],\n",
      "          [2.4833e-02],\n",
      "          [8.5850e-02],\n",
      "          [3.8453e-02],\n",
      "          [4.7897e-02],\n",
      "          [5.2896e-02],\n",
      "          [6.4943e-03],\n",
      "          [7.5359e-02],\n",
      "          [8.2139e-02],\n",
      "          [3.6387e-02],\n",
      "          [2.9117e-02],\n",
      "          [1.5626e-02]],\n",
      "\n",
      "         [[2.9138e+00],\n",
      "          [6.1204e-01],\n",
      "          [1.3374e+00],\n",
      "          [7.4702e-01],\n",
      "          [1.6107e+00],\n",
      "          [6.1061e-01],\n",
      "          [1.8223e+00],\n",
      "          [7.3072e-01],\n",
      "          [1.0870e+00],\n",
      "          [3.1742e-01],\n",
      "          [9.8597e-01],\n",
      "          [7.8883e-01],\n",
      "          [8.7475e-01],\n",
      "          [1.0054e+00],\n",
      "          [3.3024e-01],\n",
      "          [8.8945e-01],\n",
      "          [4.9449e-01],\n",
      "          [8.1584e-01],\n",
      "          [8.3332e-01],\n",
      "          [3.2003e-01],\n",
      "          [8.7316e-01],\n",
      "          [1.6844e-01],\n",
      "          [8.0598e-01],\n",
      "          [2.1508e-01],\n",
      "          [2.8677e-01],\n",
      "          [2.3242e-01],\n",
      "          [7.7493e-02],\n",
      "          [1.6440e-01],\n",
      "          [8.1981e-02],\n",
      "          [3.4099e-01],\n",
      "          [3.0061e-01],\n",
      "          [3.2263e-01]],\n",
      "\n",
      "         [[3.0704e+00],\n",
      "          [1.2705e+00],\n",
      "          [7.8412e-01],\n",
      "          [1.3930e+00],\n",
      "          [1.8217e+00],\n",
      "          [1.9041e+00],\n",
      "          [1.9174e+00],\n",
      "          [8.1950e-01],\n",
      "          [1.8795e+00],\n",
      "          [1.5245e+00],\n",
      "          [6.7510e-01],\n",
      "          [1.2665e+00],\n",
      "          [1.2572e+00],\n",
      "          [1.7678e-01],\n",
      "          [6.0267e-01],\n",
      "          [8.7926e-01],\n",
      "          [5.0109e-01],\n",
      "          [3.3979e-01],\n",
      "          [2.4326e-01],\n",
      "          [4.2080e-01],\n",
      "          [9.1964e-02],\n",
      "          [2.0306e-01],\n",
      "          [2.4722e-01],\n",
      "          [8.6880e-02],\n",
      "          [2.2386e-01],\n",
      "          [7.7070e-02],\n",
      "          [9.6282e-02],\n",
      "          [1.6033e-01],\n",
      "          [1.8149e-01],\n",
      "          [1.8054e-01],\n",
      "          [2.7748e-01],\n",
      "          [2.5118e-01]],\n",
      "\n",
      "         [[5.6505e-02],\n",
      "          [5.3808e-01],\n",
      "          [4.5559e-01],\n",
      "          [5.5811e-01],\n",
      "          [5.3677e-01],\n",
      "          [6.6210e-01],\n",
      "          [1.8110e+00],\n",
      "          [2.0393e+00],\n",
      "          [1.1458e+00],\n",
      "          [2.8399e-01],\n",
      "          [3.1663e-01],\n",
      "          [3.9534e-01],\n",
      "          [1.0457e+00],\n",
      "          [1.1565e+00],\n",
      "          [2.5818e+00],\n",
      "          [4.4622e-01],\n",
      "          [7.1880e-01],\n",
      "          [4.3910e-01],\n",
      "          [9.1134e-01],\n",
      "          [8.9254e-01],\n",
      "          [7.6973e-01],\n",
      "          [1.7538e+00],\n",
      "          [1.0775e+00],\n",
      "          [4.8424e-01],\n",
      "          [6.0984e-01],\n",
      "          [8.6520e-01],\n",
      "          [6.0135e-01],\n",
      "          [5.2315e-01],\n",
      "          [1.4625e+00],\n",
      "          [4.0650e-01],\n",
      "          [2.7559e-01],\n",
      "          [3.9630e-01]],\n",
      "\n",
      "         [[2.1928e+00],\n",
      "          [3.1296e-03],\n",
      "          [3.0692e-01],\n",
      "          [2.0347e+00],\n",
      "          [1.7639e+00],\n",
      "          [1.6255e+00],\n",
      "          [2.8894e-01],\n",
      "          [2.2684e+00],\n",
      "          [1.1945e+00],\n",
      "          [4.3865e-01],\n",
      "          [9.8642e-01],\n",
      "          [6.3963e-01],\n",
      "          [8.6955e-01],\n",
      "          [6.7891e-01],\n",
      "          [1.1457e+00],\n",
      "          [9.2692e-01],\n",
      "          [5.5271e-01],\n",
      "          [5.8698e-01],\n",
      "          [6.1722e-02],\n",
      "          [7.2553e-01],\n",
      "          [4.6001e-01],\n",
      "          [4.4284e-01],\n",
      "          [6.4097e-01],\n",
      "          [3.4597e-01],\n",
      "          [2.9528e-01],\n",
      "          [2.2227e-01],\n",
      "          [3.7734e-01],\n",
      "          [2.4692e-01],\n",
      "          [2.6961e-01],\n",
      "          [3.1999e-01],\n",
      "          [2.2463e-01],\n",
      "          [2.3100e-01]],\n",
      "\n",
      "         [[2.0572e+00],\n",
      "          [1.6547e+00],\n",
      "          [4.2433e-01],\n",
      "          [1.2594e+00],\n",
      "          [1.0565e+00],\n",
      "          [3.5109e+00],\n",
      "          [2.9901e-01],\n",
      "          [2.0836e+00],\n",
      "          [2.5492e-01],\n",
      "          [1.1819e+00],\n",
      "          [1.1105e+00],\n",
      "          [3.7983e-01],\n",
      "          [4.8677e-01],\n",
      "          [1.0953e-01],\n",
      "          [9.0753e-01],\n",
      "          [5.8136e-01],\n",
      "          [5.0149e-01],\n",
      "          [2.6348e-01],\n",
      "          [4.5488e-01],\n",
      "          [1.4923e-01],\n",
      "          [1.2585e-01],\n",
      "          [3.7444e-01],\n",
      "          [3.7572e-01],\n",
      "          [2.5947e-01],\n",
      "          [1.8136e-01],\n",
      "          [6.1978e-01],\n",
      "          [9.3654e-02],\n",
      "          [2.7423e-01],\n",
      "          [1.9901e-01],\n",
      "          [1.6599e-01],\n",
      "          [4.1208e-01],\n",
      "          [2.2212e-01]],\n",
      "\n",
      "         [[2.4791e+00],\n",
      "          [2.2292e+00],\n",
      "          [1.6372e+00],\n",
      "          [2.2626e+00],\n",
      "          [1.1766e+00],\n",
      "          [9.1920e-01],\n",
      "          [3.3221e-01],\n",
      "          [1.9232e-01],\n",
      "          [5.7908e-01],\n",
      "          [4.2362e-01],\n",
      "          [3.6295e-01],\n",
      "          [5.4755e-01],\n",
      "          [5.9160e-01],\n",
      "          [1.1529e+00],\n",
      "          [1.7708e-01],\n",
      "          [1.2608e+00],\n",
      "          [1.4761e+00],\n",
      "          [1.4335e+00],\n",
      "          [2.1865e+00],\n",
      "          [1.1241e+00],\n",
      "          [9.0112e-01],\n",
      "          [6.2877e-01],\n",
      "          [3.3784e-01],\n",
      "          [2.3818e-01],\n",
      "          [2.8556e-01],\n",
      "          [1.1211e-01],\n",
      "          [4.6348e-01],\n",
      "          [3.8697e-01],\n",
      "          [5.5245e-01],\n",
      "          [1.2990e+00],\n",
      "          [4.9101e-01],\n",
      "          [1.2546e+00]],\n",
      "\n",
      "         [[1.2620e+00],\n",
      "          [1.9116e+00],\n",
      "          [1.0287e+00],\n",
      "          [8.7076e-01],\n",
      "          [6.6805e-01],\n",
      "          [2.7921e-01],\n",
      "          [9.9836e-01],\n",
      "          [1.7332e+00],\n",
      "          [1.2003e+00],\n",
      "          [1.7684e+00],\n",
      "          [9.8271e-01],\n",
      "          [3.7291e-01],\n",
      "          [1.8621e-01],\n",
      "          [3.1636e-01],\n",
      "          [1.0715e+00],\n",
      "          [1.7282e+00],\n",
      "          [4.9762e-01],\n",
      "          [1.1978e+00],\n",
      "          [1.0135e+00],\n",
      "          [7.3670e-01],\n",
      "          [1.5200e-01],\n",
      "          [2.7175e-01],\n",
      "          [6.0558e-01],\n",
      "          [5.7928e-01],\n",
      "          [4.4750e-01],\n",
      "          [6.1064e-01],\n",
      "          [7.3591e-01],\n",
      "          [5.9345e-01],\n",
      "          [4.2098e-01],\n",
      "          [2.5745e-01],\n",
      "          [2.0993e-01],\n",
      "          [2.4060e-01]],\n",
      "\n",
      "         [[2.2400e+00],\n",
      "          [1.9747e+00],\n",
      "          [2.2317e+00],\n",
      "          [2.4456e+00],\n",
      "          [3.2414e+00],\n",
      "          [1.2589e+00],\n",
      "          [4.3504e-01],\n",
      "          [5.8801e-01],\n",
      "          [9.2022e-01],\n",
      "          [3.2793e-01],\n",
      "          [1.2866e+00],\n",
      "          [4.0061e-01],\n",
      "          [1.2738e+00],\n",
      "          [3.2418e-01],\n",
      "          [2.8142e-01],\n",
      "          [2.1137e-01],\n",
      "          [1.9995e-01],\n",
      "          [3.4557e-01],\n",
      "          [1.9229e-01],\n",
      "          [2.2255e-01],\n",
      "          [1.0301e-01],\n",
      "          [1.6803e-01],\n",
      "          [1.8892e-01],\n",
      "          [2.3077e-01],\n",
      "          [4.0461e-01],\n",
      "          [1.0839e-01],\n",
      "          [2.4477e-01],\n",
      "          [2.4921e-01],\n",
      "          [2.6972e-01],\n",
      "          [9.7195e-02],\n",
      "          [1.6877e-01],\n",
      "          [1.0658e-01]],\n",
      "\n",
      "         [[1.1786e+00],\n",
      "          [1.9685e+00],\n",
      "          [1.9040e+00],\n",
      "          [1.9294e+00],\n",
      "          [6.2808e-01],\n",
      "          [2.3307e-01],\n",
      "          [8.3817e-01],\n",
      "          [8.5584e-01],\n",
      "          [3.6508e-01],\n",
      "          [3.8687e-01],\n",
      "          [2.5498e-01],\n",
      "          [1.8926e-01],\n",
      "          [1.3610e-01],\n",
      "          [5.0223e-02],\n",
      "          [2.5694e-01],\n",
      "          [9.4025e-02],\n",
      "          [2.7355e-01],\n",
      "          [9.4589e-02],\n",
      "          [1.1434e-01],\n",
      "          [1.6584e-01],\n",
      "          [1.8793e-01],\n",
      "          [3.5801e-01],\n",
      "          [3.6764e-01],\n",
      "          [4.7552e-01],\n",
      "          [5.8621e-01],\n",
      "          [7.2586e-01],\n",
      "          [9.4740e-01],\n",
      "          [6.7906e-01],\n",
      "          [6.2252e-01],\n",
      "          [9.7859e-01],\n",
      "          [1.3845e+00],\n",
      "          [8.6279e-01]],\n",
      "\n",
      "         [[3.8249e-01],\n",
      "          [1.2504e+00],\n",
      "          [3.0314e-01],\n",
      "          [2.8015e-01],\n",
      "          [1.3426e-01],\n",
      "          [1.9944e-01],\n",
      "          [2.3709e-01],\n",
      "          [4.1441e-01],\n",
      "          [1.1243e+00],\n",
      "          [1.0483e+00],\n",
      "          [4.0101e-01],\n",
      "          [4.1108e-01],\n",
      "          [1.9434e-01],\n",
      "          [1.2625e-01],\n",
      "          [8.8170e-02],\n",
      "          [2.7596e-01],\n",
      "          [2.2454e-01],\n",
      "          [5.6806e-01],\n",
      "          [4.0513e-01],\n",
      "          [2.5850e-01],\n",
      "          [2.0584e-01],\n",
      "          [1.8154e-01],\n",
      "          [1.5227e-02],\n",
      "          [5.6874e-02],\n",
      "          [8.4277e-02],\n",
      "          [3.8347e-01],\n",
      "          [2.3683e-01],\n",
      "          [1.8411e-01],\n",
      "          [9.4137e-02],\n",
      "          [1.1974e-01],\n",
      "          [6.5755e-02],\n",
      "          [6.6999e-02]],\n",
      "\n",
      "         [[1.8940e+00],\n",
      "          [1.2631e+00],\n",
      "          [9.8263e-01],\n",
      "          [3.3088e-01],\n",
      "          [8.3183e-01],\n",
      "          [7.4156e-01],\n",
      "          [3.6970e-01],\n",
      "          [3.7404e-01],\n",
      "          [3.2455e-01],\n",
      "          [2.7083e-01],\n",
      "          [8.1507e-02],\n",
      "          [1.6948e-01],\n",
      "          [1.7673e-01],\n",
      "          [1.9007e-01],\n",
      "          [6.4592e-02],\n",
      "          [6.2615e-02],\n",
      "          [6.4161e-02],\n",
      "          [5.1672e-02],\n",
      "          [8.3872e-02],\n",
      "          [1.5971e-01],\n",
      "          [2.4449e-02],\n",
      "          [3.1213e-02],\n",
      "          [4.1221e-02],\n",
      "          [5.4052e-02],\n",
      "          [7.7698e-02],\n",
      "          [9.2437e-02],\n",
      "          [5.4980e-02],\n",
      "          [4.4199e-02],\n",
      "          [7.9233e-02],\n",
      "          [1.3706e-01],\n",
      "          [4.1928e-02],\n",
      "          [3.5806e-02]],\n",
      "\n",
      "         [[2.6908e+00],\n",
      "          [4.4184e+00],\n",
      "          [2.1508e+00],\n",
      "          [6.1407e-01],\n",
      "          [5.0467e-01],\n",
      "          [4.4469e-01],\n",
      "          [4.2411e-01],\n",
      "          [1.2064e+00],\n",
      "          [2.8051e+00],\n",
      "          [2.3750e+00],\n",
      "          [3.7159e+00],\n",
      "          [1.6183e+00],\n",
      "          [8.9924e-01],\n",
      "          [4.2258e-01],\n",
      "          [3.8546e-01],\n",
      "          [3.9703e-01],\n",
      "          [6.9447e-01],\n",
      "          [1.6486e+00],\n",
      "          [2.5621e+00],\n",
      "          [3.0782e+00],\n",
      "          [1.1294e+00],\n",
      "          [7.5205e-01],\n",
      "          [7.8271e-01],\n",
      "          [2.4346e-01],\n",
      "          [1.3851e-01],\n",
      "          [3.3269e-01],\n",
      "          [9.0182e-01],\n",
      "          [6.5096e-01],\n",
      "          [1.6520e+00],\n",
      "          [7.7885e-01],\n",
      "          [5.6660e-01],\n",
      "          [4.9086e-01]],\n",
      "\n",
      "         [[1.6138e+00],\n",
      "          [1.5158e+00],\n",
      "          [6.2443e-01],\n",
      "          [4.3379e-01],\n",
      "          [4.4482e-01],\n",
      "          [4.1728e-01],\n",
      "          [4.5788e-01],\n",
      "          [1.0527e+00],\n",
      "          [8.5634e-01],\n",
      "          [6.4457e-01],\n",
      "          [1.1143e+00],\n",
      "          [7.7887e-01],\n",
      "          [5.9994e-01],\n",
      "          [2.4686e-01],\n",
      "          [2.1652e-01],\n",
      "          [1.8928e-01],\n",
      "          [3.0510e-01],\n",
      "          [6.0393e-01],\n",
      "          [2.1046e-01],\n",
      "          [6.1848e-01],\n",
      "          [4.7447e-01],\n",
      "          [5.7075e-01],\n",
      "          [5.5939e-01],\n",
      "          [1.0988e-01],\n",
      "          [7.3084e-02],\n",
      "          [1.5228e-01],\n",
      "          [3.8338e-01],\n",
      "          [1.4166e-01],\n",
      "          [3.4571e-01],\n",
      "          [1.6391e-01],\n",
      "          [2.8102e-01],\n",
      "          [5.0121e-01]],\n",
      "\n",
      "         [[4.2542e+00],\n",
      "          [5.6743e+00],\n",
      "          [1.2796e+00],\n",
      "          [3.1222e-01],\n",
      "          [5.2192e-02],\n",
      "          [5.8899e-01],\n",
      "          [1.5575e+00],\n",
      "          [1.0674e+00],\n",
      "          [4.8160e-01],\n",
      "          [5.4321e-01],\n",
      "          [9.5646e-01],\n",
      "          [5.7571e-01],\n",
      "          [6.1251e-01],\n",
      "          [4.7253e-01],\n",
      "          [5.1347e-01],\n",
      "          [7.7789e-02],\n",
      "          [2.3412e-01],\n",
      "          [3.2498e-01],\n",
      "          [7.5009e-02],\n",
      "          [2.9915e-01],\n",
      "          [4.5270e-01],\n",
      "          [2.2228e-01],\n",
      "          [2.2752e-01],\n",
      "          [3.4865e-01],\n",
      "          [1.2956e-01],\n",
      "          [2.5894e-01],\n",
      "          [1.4975e-01],\n",
      "          [5.5077e-09],\n",
      "          [2.4180e-01],\n",
      "          [2.6049e-01],\n",
      "          [9.0809e-02],\n",
      "          [2.8764e-01]],\n",
      "\n",
      "         [[4.5693e+00],\n",
      "          [4.5982e+00],\n",
      "          [3.3513e+00],\n",
      "          [2.4546e+00],\n",
      "          [2.8489e+00],\n",
      "          [8.1322e-01],\n",
      "          [1.1424e+00],\n",
      "          [1.2657e+00],\n",
      "          [8.6118e-01],\n",
      "          [7.5594e-01],\n",
      "          [1.8118e-01],\n",
      "          [7.6514e-01],\n",
      "          [3.5025e-01],\n",
      "          [2.4259e-01],\n",
      "          [2.8837e-01],\n",
      "          [2.0516e-01],\n",
      "          [1.3625e-01],\n",
      "          [1.1901e-01],\n",
      "          [1.5297e-01],\n",
      "          [1.3890e-01],\n",
      "          [2.5127e-01],\n",
      "          [9.1623e-02],\n",
      "          [1.6427e-01],\n",
      "          [1.4259e-01],\n",
      "          [9.1718e-02],\n",
      "          [6.9387e-02],\n",
      "          [2.0735e-01],\n",
      "          [4.6873e-02],\n",
      "          [4.4241e-02],\n",
      "          [6.0161e-02],\n",
      "          [1.3597e-01],\n",
      "          [9.8323e-02]]]], device='cuda:0')\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for y_recur_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Updated amax and amin for activation quantizer: max_min: tensor([[[10.3215],\n",
      "         [16.9610],\n",
      "         [23.1518],\n",
      "         [25.2975],\n",
      "         [16.6064],\n",
      "         [19.9537],\n",
      "         [33.3860],\n",
      "         [24.3911],\n",
      "         [28.7953],\n",
      "         [29.5411],\n",
      "         [ 9.1129],\n",
      "         [ 9.3612],\n",
      "         [36.5064],\n",
      "         [15.6597],\n",
      "         [22.8429],\n",
      "         [37.4131]]], device='cuda:0')\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for y_pre_output_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Updated amax and amin for activation quantizer: max_min: tensor([[[14.2084],\n",
      "         [16.6862],\n",
      "         [22.6354],\n",
      "         [25.0948],\n",
      "         [16.7284],\n",
      "         [22.3361],\n",
      "         [33.3925],\n",
      "         [25.3262],\n",
      "         [31.2691],\n",
      "         [33.4683],\n",
      "         [ 9.1355],\n",
      "         [ 9.8368],\n",
      "         [36.5104],\n",
      "         [15.5724],\n",
      "         [22.7189],\n",
      "         [40.8204]]], device='cuda:0')\n",
      "Reset statistics for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for S4BlockRecurrent\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Finished calibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (78/79) | Loss: 0.768 | Acc: 76.440% (7644/10000): : 79it [00:31,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 76.44, Loss: 0.7676162231194822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.7676162231194822, 'acc': 76.44}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure still quantised\n",
    "s4_block = q_trainer.model.s4_layers[0][1]\n",
    "torch.unique(torch.view_as_real(s4_block.dA)[15,:,:])\n",
    "# Check activations are quantised, redo static quantisation\n",
    "q_trainer.calibrate(num_batches=1)\n",
    "q_trainer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loading from sweep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 16]             32\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 16, 784]             --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 16]             3,104\n",
      "|    |    └─Identity: 3-2                [-1, 784, 16]             --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 16]             --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 16]             544\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 16, 784]             --\n",
      "├─Linear: 1-2                            [-1, 10]                  170\n",
      "==========================================================================================\n",
      "Total params: 3,850\n",
      "Trainable params: 3,850\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.40\n",
      "==========================================================================================\n",
      "Replacing S4Block with S4BlockRecurrent\n",
      "[*] Quantizing 0\n",
      "Quantized weights for dA\n",
      "Quantized weights for dB\n",
      "Quantized weights for dC\n",
      "Quantized weights for D\n",
      "[*] Replacing 0 with S4BlockRecurrent(\n",
      "  (layer_activation): GELU(approximate='none')\n",
      "  (mult_activation): Identity()\n",
      "  (drop): Identity()\n",
      "  (output_linear): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (1): GLU(dim=-1)\n",
      "  )\n",
      ")\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before 0\n",
      "Quantized activations inside S4BlockRecurrent\n",
      "Registered clipping hook on state quantizer\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=[-2], static_dims_to_reduce=[0, -1], num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to 0\n",
      "Quantized input activations of S4BlockRecurrent. Inserted functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=[-2], static_dims_to_reduce=[0, -1], num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') before S4BlockRecurrent\n",
      "Replacing Linear with QLinear\n",
      "[*] Quantizing encoder\n",
      "Quantized weights for weight\n",
      "[*] Replacing encoder with QLinear()\n",
      "[*] Quantizing 0\n",
      "Quantized weights for weight\n",
      "[*] Replacing 0 with QLinear()\n",
      "[*] Quantizing decoder\n",
      "Quantized weights for weight\n",
      "[*] Replacing decoder with QLinear()\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before encoder\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to encoder\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before 0\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to 0\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before decoder\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to decoder\n",
      "Quantized input activations of QLinear. Inserted functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') before QLinear\n",
      "Replacing GELU with QGELU\n",
      "[*] Quantizing layer_activation\n",
      "[*] Replacing layer_activation with QGELU()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S4DModel(\n",
       "  (encoder): Sequential(\n",
       "    (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "    (1): QLinear()\n",
       "  )\n",
       "  (s4_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "      (1): S4BlockRecurrent(\n",
       "        (layer_activation): QGELU()\n",
       "        (mult_activation): Identity()\n",
       "        (drop): Identity()\n",
       "        (output_linear): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "            (1): QLinear()\n",
       "          )\n",
       "          (1): GLU(dim=-1)\n",
       "        )\n",
       "        (state_quantizer): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-1, -2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "        (y_recur_quantizer): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "        (y_pre_output_quantizer): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): Identity()\n",
       "  )\n",
       "  (dropouts): ModuleList(\n",
       "    (0): Dropout1d(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "    (1): QLinear()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test loading from sweep data\n",
    "\n",
    "from quantize import set_up_quantizers\n",
    "from pathlib import Path\n",
    "\n",
    "model_path = Path(r\"/home/leo/QuantisedSSM/S4/log/sweep_asymmetric_symmetric/asymmetric_8bits_all_weights_acts_perchannel_seed_0/QAT_9_static\")\n",
    "fname = model_path.parents[1] / \"config_seed0.yaml\"\n",
    "resume_checkpoint =  model_path / \"checkpoint\" / \"ckpt.pth\"\n",
    "\n",
    "config_yaml = read_yaml(fname)\n",
    "\n",
    "q_config_fname = model_path.parent / \"q_config.yaml\"\n",
    "q_config_yaml = read_yaml(q_config_fname)\n",
    "q_config = ConfigParser(q_config_yaml, resume_checkpoint, modification=None, save_log=False)\n",
    "\n",
    "modification = {\"run_name\": q_config[\"run_name\"]}\n",
    "\n",
    "config = ConfigParser(config_yaml, None, modification=modification, save_log=False)\n",
    "\n",
    "q_trainer = set_up_trainer(config)\n",
    "set_up_quantizers(q_trainer.model, q_config)\n",
    "# q_trainer.load_checkpoint(resume_checkpoint)\n",
    "\n",
    "q_trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Flatten: 1-1                           [-1, 784]                 --\n",
      "├─MLP: 1-2                               [-1, 10]                  --\n",
      "|    └─Linear: 2-1                       [-1, 64]                  50,240\n",
      "|    └─BatchNorm1d: 2-2                  [-1, 64]                  128\n",
      "|    └─ReLU: 2-3                         [-1, 64]                  --\n",
      "|    └─Dropout: 2-4                      [-1, 64]                  --\n",
      "|    └─Linear: 2-5                       [-1, 10]                  650\n",
      "|    └─Dropout: 2-6                      [-1, 10]                  --\n",
      "==========================================================================================\n",
      "Total params: 51,018\n",
      "Trainable params: 51,018\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.10\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.19\n",
      "Estimated Total Size (MB): 0.20\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): MLP(\n",
       "    (0): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (5): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test loading from sweep data\n",
    "\n",
    "from quantize import set_up_quantizers\n",
    "from pathlib import Path\n",
    "\n",
    "fname = r\"/home/leo/QuantisedSSM/S4/configs/MLP_config.yaml\"\n",
    "resume_checkpoint = Path(r\"/home/leo/QuantisedSSM/S4/log/test\") / \"checkpoint\" / \"ckpt.pth\"\n",
    "\n",
    "config_yaml = read_yaml(fname)\n",
    "\n",
    "# q_config_fname = r\"/home/leo/QuantisedSSM/S4/configs/q_config_MLP.yaml\"\n",
    "# q_config_yaml = read_yaml(q_config_fname)\n",
    "# q_config = ConfigParser(q_config_yaml, resume_checkpoint, modification=None, save_log=False)\n",
    "# modification = {\"run_name\": q_config[\"run_name\"]}\n",
    "\n",
    "modification ={\"seed\": 0}\n",
    "\n",
    "config = ConfigParser(config_yaml, None, modification=modification, save_log=False)\n",
    "\n",
    "q_trainer = set_up_trainer(config)\n",
    "# set_up_quantizers(q_trainer, q_config)\n",
    "# q_trainer.load_checkpoint(resume_checkpoint)\n",
    "\n",
    "q_trainer.save_dir = Path(r\"/home/leo/QuantisedSSM/S4/log/test\")\n",
    "\n",
    "q_trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.349 | Acc: 90.362% (45181/50000): : 98it [00:17,  5.65it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.193 | Acc: 94.360% (9436/10000): : 20it [00:03,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at /home/leo/QuantisedSSM/S4/log/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.187 | Acc: 94.430% (9443/10000): : 20it [00:03,  6.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.19265839457511902,\n",
       " 'val_acc': 94.36,\n",
       " 'test_loss': 0.18653013035655022,\n",
       " 'test_acc': 94.43,\n",
       " 'epoch': 1,\n",
       " 'train_loss': 0.3486754568863888,\n",
       " 'train_acc': 90.362,\n",
       " 'lr': [0.009938441702975689]}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q_trainer.disable_all_quantization()\n",
    "# q_trainer.train_epoch(1)\n",
    "\n",
    "# q_trainer.set_static_quantization()\n",
    "\n",
    "# q_trainer.quantize_all_weights()\n",
    "# q_trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calibration with 1 batches\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Updated amax and amin for activation quantizer: max_min: (tensor([[2.8215]], device='cuda:0'), tensor([[-0.4242]], device='cuda:0'))\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Updated amax and amin for activation quantizer: max_min: (tensor([[3.8583]], device='cuda:0'), tensor([[0.]], device='cuda:0'))\n",
      "Reset statistics for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Finished calibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.187 | Acc: 94.430% (9443/10000): : 20it [00:02,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 94.43, Loss: 0.18653013035655022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.18653013035655022, 'acc': 94.43}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_trainer.calibrate(num_batches=1)\n",
    "q_trainer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set static quantization without setting amax/amin. Run calibration first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mq_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_static_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m q_trainer\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../train.py:301\u001b[0m, in \u001b[0;36mTrainer.set_static_quantization\u001b[0;34m(self, module_name_to_exclude)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_static_quantization\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name_to_exclude\u001b[38;5;241m=\u001b[39m[]):\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Set static quantization for all quantizers in the model'''\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     \u001b[43mset_static_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name_to_exclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_name_to_exclude\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../quantize.py:50\u001b[0m, in \u001b[0;36mset_static_quantization\u001b[0;34m(module, module_name_to_exclude)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(child, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_static_quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     48\u001b[0m         child\u001b[38;5;241m.\u001b[39mset_static_quantization()\n\u001b[0;32m---> 50\u001b[0m \u001b[43mapply_function_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_call_on_child\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name_to_exclude\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../S4/quantization/q_utils.py:53\u001b[0m, in \u001b[0;36mapply_function_to_module\u001b[0;34m(module, function, module_name_to_exclude)\u001b[0m\n\u001b[1;32m     51\u001b[0m     function(child)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Recursively call the function for nested modules\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mapply_function_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name_to_exclude\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../S4/quantization/q_utils.py:53\u001b[0m, in \u001b[0;36mapply_function_to_module\u001b[0;34m(module, function, module_name_to_exclude)\u001b[0m\n\u001b[1;32m     51\u001b[0m     function(child)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Recursively call the function for nested modules\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mapply_function_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name_to_exclude\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../S4/quantization/q_utils.py:51\u001b[0m, in \u001b[0;36mapply_function_to_module\u001b[0;34m(module, function, module_name_to_exclude)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m([x \u001b[38;5;241m==\u001b[39m name \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m module_name_to_exclude]):\n\u001b[0;32m---> 51\u001b[0m         \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Recursively call the function for nested modules\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     apply_function_to_module(child, function, module_name_to_exclude)\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../quantize.py:48\u001b[0m, in \u001b[0;36mset_static_quantization.<locals>.to_call_on_child\u001b[0;34m(child)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_call_on_child\u001b[39m(child):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(child, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_static_quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_static_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/QuantisedSSM/S4/notebooks/../../S4/quantization/quantizers.py:109\u001b[0m, in \u001b[0;36mActivationQuantizer.set_static_quantization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Make sure amax not default value\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamax \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set static quantization without setting amax/amin. Run calibration first\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_static_flag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnabled flag for static quantization. Now using static quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set static quantization without setting amax/amin. Run calibration first"
     ]
    }
   ],
   "source": [
    "q_trainer.set_static_quantization()\n",
    "q_trainer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantisedSSM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
