{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "parent = os.path.abspath(os.path.join(path, os.pardir))\n",
    "sys.path.append( parent )\n",
    "subparent = os.path.abspath( os.path.join(parent, os.pardir) )\n",
    "sys.path.append( subparent )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Pykeops installation found.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from utils import read_yaml\n",
    "from parse_arguments import ConfigParser\n",
    "from train import set_up_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training FP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fname = r'../configs/S4D_small.yaml' # Path to FP model config file\n",
    "# resume_checkpoint = r\"../log/S4D_small/fp32_16heads/checkpoint/ckpt.pth\" # Path to checkpoint to resume training from\n",
    "resume_checkpoint = None\n",
    "\n",
    "config_yaml = read_yaml(config_fname)\n",
    "# modification = {\"model;type\": 32} # Optional modification to the config\n",
    "modification = None\n",
    "config = ConfigParser(config_yaml, resume_checkpoint, modification=modification, save_log=False) # Set save_log to True to save trained model and logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up FP trainer\n",
    "\n",
    "Hyperparams are set in config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 16]             32\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 16, 784]             --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 16]             3,104\n",
      "|    |    └─Identity: 3-2                [-1, 784, 16]             --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 16]             --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 16]             544\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 16, 784]             --\n",
      "├─Linear: 1-2                            [-1, 10]                  170\n",
      "==========================================================================================\n",
      "Total params: 3,850\n",
      "Trainable params: 3,850\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.40\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "trainer = set_up_trainer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 1.586 | Acc: 44.534% (22267/50000): : 98it [00:06, 14.76it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.686 | Acc: 78.080% (7808/10000): : 20it [00:01, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.675 | Acc: 78.160% (7816/10000): : 20it [00:01, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Acc: 44.534, Val Acc: 78.08, Test Acc: 78.16, LR: [0.009938441702975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.469 | Acc: 85.384% (42692/50000): : 98it [00:06, 14.50it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.369 | Acc: 88.740% (8874/10000): : 20it [00:01, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.347 | Acc: 89.270% (8927/10000): : 20it [00:01, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Acc: 85.384, Val Acc: 88.74, Test Acc: 89.27, LR: [0.009755282581475769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.304 | Acc: 91.156% (45578/50000): : 98it [00:06, 14.93it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.277 | Acc: 91.850% (9185/10000): : 20it [00:01, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.260 | Acc: 92.150% (9215/10000): : 20it [00:01, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Acc: 91.156, Val Acc: 91.85, Test Acc: 92.15, LR: [0.00945503262094184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.235 | Acc: 93.300% (46650/50000): : 98it [00:06, 14.89it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.207 | Acc: 94.340% (9434/10000): : 20it [00:01, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.194 | Acc: 94.610% (9461/10000): : 20it [00:01, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Acc: 93.3, Val Acc: 94.34, Test Acc: 94.61, LR: [0.009045084971874739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.196 | Acc: 94.518% (47259/50000): : 98it [00:06, 14.98it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.182 | Acc: 94.620% (9462/10000): : 20it [00:01, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.170 | Acc: 95.080% (9508/10000): : 20it [00:01, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Acc: 94.518, Val Acc: 94.62, Test Acc: 95.08, LR: [0.008535533905932738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.173 | Acc: 95.122% (47561/50000): : 98it [00:06, 14.70it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.166 | Acc: 95.120% (9512/10000): : 20it [00:01, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.153 | Acc: 95.740% (9574/10000): : 20it [00:01, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Acc: 95.122, Val Acc: 95.12, Test Acc: 95.74, LR: [0.007938926261462366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.156 | Acc: 95.556% (47778/50000): : 98it [00:06, 14.35it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.150 | Acc: 95.720% (9572/10000): : 20it [00:01, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.142 | Acc: 95.770% (9577/10000): : 20it [00:01, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Acc: 95.556, Val Acc: 95.72, Test Acc: 95.77, LR: [0.007269952498697735]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.147 | Acc: 95.786% (47893/50000): : 98it [00:06, 14.99it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.141 | Acc: 95.850% (9585/10000): : 20it [00:01, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.128 | Acc: 96.170% (9617/10000): : 20it [00:01, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Acc: 95.786, Val Acc: 95.85, Test Acc: 96.17, LR: [0.006545084971874738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.132 | Acc: 96.170% (48085/50000): : 98it [00:06, 14.74it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.133 | Acc: 96.050% (9605/10000): : 20it [00:01, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.126 | Acc: 96.360% (9636/10000): : 20it [00:01, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Acc: 96.17, Val Acc: 96.05, Test Acc: 96.36, LR: [0.005782172325201155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.126 | Acc: 96.380% (48190/50000): : 98it [00:06, 14.93it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.135 | Acc: 96.110% (9611/10000): : 20it [00:01, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.126 | Acc: 96.310% (9631/10000): : 20it [00:01, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Acc: 96.38, Val Acc: 96.11, Test Acc: 96.31, LR: [0.005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.123 | Acc: 96.464% (48232/50000): : 98it [00:06, 14.45it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.129 | Acc: 96.120% (9612/10000): : 20it [00:01, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.121 | Acc: 96.540% (9654/10000): : 20it [00:01, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Acc: 96.464, Val Acc: 96.12, Test Acc: 96.54, LR: [0.004217827674798847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.112 | Acc: 96.720% (48360/50000): : 98it [00:06, 14.56it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.118 | Acc: 96.480% (9648/10000): : 20it [00:01, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.116 | Acc: 96.500% (9650/10000): : 20it [00:01, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Acc: 96.72, Val Acc: 96.48, Test Acc: 96.5, LR: [0.0034549150281252636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.109 | Acc: 96.760% (48380/50000): : 98it [00:06, 14.90it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.112 | Acc: 96.780% (9678/10000): : 20it [00:01, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.110 | Acc: 96.660% (9666/10000): : 20it [00:01, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Acc: 96.76, Val Acc: 96.78, Test Acc: 96.66, LR: [0.0027300475013022664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.104 | Acc: 96.926% (48463/50000): : 98it [00:06, 14.56it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.112 | Acc: 96.670% (9667/10000): : 20it [00:01, 16.76it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.109 | Acc: 96.810% (9681/10000): : 20it [00:01, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Acc: 96.926, Val Acc: 96.67, Test Acc: 96.81, LR: [0.0020610737385376348]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.100 | Acc: 97.054% (48527/50000): : 98it [00:06, 14.18it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.104 | Acc: 96.920% (9692/10000): : 20it [00:01, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.160% (9716/10000): : 20it [00:01, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Acc: 97.054, Val Acc: 96.92, Test Acc: 97.16, LR: [0.0014644660940672626]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.097 | Acc: 97.194% (48597/50000): : 98it [00:06, 14.45it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.106 | Acc: 96.740% (9674/10000): : 20it [00:01, 16.05it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.099 | Acc: 97.110% (9711/10000): : 20it [00:01, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Acc: 97.194, Val Acc: 96.74, Test Acc: 97.11, LR: [0.0009549150281252633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.094 | Acc: 97.288% (48644/50000): : 98it [00:06, 14.61it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.101 | Acc: 97.070% (9707/10000): : 20it [00:01, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.093 | Acc: 97.150% (9715/10000): : 20it [00:01, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Acc: 97.288, Val Acc: 97.07, Test Acc: 97.15, LR: [0.0005449673790581611]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.091 | Acc: 97.316% (48658/50000): : 98it [00:06, 14.10it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.100 | Acc: 97.020% (9702/10000): : 20it [00:01, 15.83it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.093 | Acc: 97.190% (9719/10000): : 20it [00:01, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Acc: 97.316, Val Acc: 97.02, Test Acc: 97.19, LR: [0.00024471741852423234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.090 | Acc: 97.390% (48695/50000): : 98it [00:06, 14.90it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.099 | Acc: 97.080% (9708/10000): : 20it [00:01, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.092 | Acc: 97.280% (9728/10000): : 20it [00:01, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Acc: 97.39, Val Acc: 97.08, Test Acc: 97.28, LR: [6.15582970243117e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.089 | Acc: 97.408% (48704/50000): : 98it [00:06, 14.93it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.020% (9702/10000): : 20it [00:01, 16.92it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.091 | Acc: 97.330% (9733/10000): : 20it [00:01, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Acc: 97.408, Val Acc: 97.02, Test Acc: 97.33, LR: [0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.089 | Acc: 97.432% (48716/50000): : 98it [00:06, 14.72it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.020% (9702/10000): : 20it [00:01, 16.89it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.091 | Acc: 97.330% (9733/10000): : 20it [00:01, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Acc: 97.432, Val Acc: 97.02, Test Acc: 97.33, LR: [6.155829702431115e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.089 | Acc: 97.420% (48710/50000): : 98it [00:06, 14.99it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.020% (9702/10000): : 20it [00:01, 16.95it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.091 | Acc: 97.320% (9732/10000): : 20it [00:01, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Acc: 97.42, Val Acc: 97.02, Test Acc: 97.32, LR: [0.00024471741852423126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.089 | Acc: 97.358% (48679/50000): : 98it [00:06, 14.97it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.010% (9701/10000): : 20it [00:01, 16.92it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.091 | Acc: 97.270% (9727/10000): : 20it [00:01, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Acc: 97.358, Val Acc: 97.01, Test Acc: 97.27, LR: [0.0005449673790581606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.090 | Acc: 97.402% (48701/50000): : 98it [00:06, 14.71it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.099 | Acc: 97.060% (9706/10000): : 20it [00:01, 16.91it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.092 | Acc: 97.250% (9725/10000): : 20it [00:01, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Acc: 97.402, Val Acc: 97.06, Test Acc: 97.25, LR: [0.0009549150281252623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.091 | Acc: 97.350% (48675/50000): : 98it [00:06, 14.93it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.150% (9715/10000): : 20it [00:01, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found. Saving checkpoint at ../S4/log/S4D_small/0604_131952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.092 | Acc: 97.330% (9733/10000): : 20it [00:01, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Acc: 97.35, Val Acc: 97.15, Test Acc: 97.33, LR: [0.0014644660940672616]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.092 | Acc: 97.264% (48632/50000): : 98it [00:06, 14.93it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.102 | Acc: 96.980% (9698/10000): : 20it [00:01, 16.83it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.094 | Acc: 97.140% (9714/10000): : 20it [00:01, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Acc: 97.264, Val Acc: 96.98, Test Acc: 97.14, LR: [0.002061073738537634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.095 | Acc: 97.274% (48637/50000): : 98it [00:06, 14.61it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.104 | Acc: 96.940% (9694/10000): : 20it [00:01, 16.89it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.190% (9719/10000): : 20it [00:01, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Acc: 97.274, Val Acc: 96.94, Test Acc: 97.19, LR: [0.002730047501302265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.094 | Acc: 97.184% (48592/50000): : 98it [00:06, 14.93it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.097 | Acc: 97.080% (9708/10000): : 20it [00:01, 16.64it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.092 | Acc: 97.340% (9734/10000): : 20it [00:01, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Acc: 97.184, Val Acc: 97.08, Test Acc: 97.34, LR: [0.003454915028125262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.097 | Acc: 97.122% (48561/50000): : 98it [00:06, 14.90it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.104 | Acc: 96.960% (9696/10000): : 20it [00:01, 16.83it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.098 | Acc: 97.220% (9722/10000): : 20it [00:01, 16.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Acc: 97.122, Val Acc: 96.96, Test Acc: 97.22, LR: [0.004217827674798845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN - Batch Idx: (97/98) | Loss: 0.098 | Acc: 97.074% (48537/50000): : 98it [00:06, 14.49it/s]\n",
      "VAL - Batch Idx: (19/20) | Loss: 0.107 | Acc: 96.800% (9680/10000): : 20it [00:01, 16.72it/s]\n",
      "TEST - Batch Idx: (19/20) | Loss: 0.105 | Acc: 96.810% (9681/10000): : 20it [00:01, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Acc: 97.074, Val Acc: 96.8, Test Acc: 96.81, LR: [0.004999999999999998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 0.105 | Acc: 96.810% (9681/10000): : 20it [00:01, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 96.81, Loss: 0.10494149117730558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.10494149117730558, 'acc': 96.81}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the set_up_quantizers function to perform quantisation. Quantization parameters are set in the qconfig file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Generating MNIST Classification Dataset...\n",
      "[*] Train set size: 50000\n",
      "[*] Validation set size: 10000\n",
      "[*] Test set size: 10000\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 784, 16]             32\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─S4Block: 2-1                      [-1, 16, 784]             --\n",
      "|    |    └─FFTConv: 3-1                 [-1, 784, 16]             3,104\n",
      "|    |    └─Identity: 3-2                [-1, 784, 16]             --\n",
      "|    |    └─Identity: 3-3                [-1, 784, 16]             --\n",
      "|    |    └─Sequential: 3-4              [-1, 784, 16]             544\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Dropout1d: 2-2                    [-1, 16, 784]             --\n",
      "├─Linear: 1-2                            [-1, 10]                  170\n",
      "==========================================================================================\n",
      "Total params: 3,850\n",
      "Trainable params: 3,850\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.40\n",
      "==========================================================================================\n",
      "[*] Quantizing 0\n",
      "Quantized weights for dA\n",
      "Quantized weights for dB\n",
      "Quantized weights for dC\n",
      "Quantized weights for D\n",
      "[*] Replacing 0 with S4BlockRecurrent(\n",
      "  (layer_activation): GELU(approximate='none')\n",
      "  (mult_activation): Identity()\n",
      "  (drop): Identity()\n",
      "  (output_linear): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (1): GLU(dim=-1)\n",
      "  )\n",
      ")\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before 0\n",
      "Quantized activations inside S4BlockRecurrent\n",
      "Registered clipping hook on state quantizer\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=[-2], static_dims_to_reduce=[0, -1], num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to 0\n",
      "Quantized input activations of S4BlockRecurrent. Inserted functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=[-2], static_dims_to_reduce=[0, -1], num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') before S4BlockRecurrent\n",
      "[*] Quantizing encoder\n",
      "Quantized weights for weight\n",
      "[*] Replacing encoder with QLinear()\n",
      "[*] Quantizing 0\n",
      "Quantized weights for weight\n",
      "[*] Replacing 0 with QLinear()\n",
      "[*] Quantizing decoder\n",
      "Quantized weights for weight\n",
      "[*] Replacing decoder with QLinear()\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before encoder\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to encoder\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before 0\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to 0\n",
      "[*] Inserting ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16) before decoder\n",
      "[*] Passed in functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') to decoder\n",
      "Quantized input activations of QLinear. Inserted functools.partial(<class 'S4.quantization.quantizers.ActivationQuantizer'>, mode='asymmetric', dims_to_reduce=None, static_dims_to_reduce=None, num_bits=8, zero_point_bits=16, percentile=99.999, unsigned=False, narrow_range=False, fake_real='fake') before QLinear\n",
      "[*] Quantizing layer_activation\n",
      "[*] Replacing layer_activation with QGELU()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S4DModel(\n",
       "  (encoder): Sequential(\n",
       "    (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "    (1): QLinear()\n",
       "  )\n",
       "  (s4_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "      (1): S4BlockRecurrent(\n",
       "        (layer_activation): QGELU()\n",
       "        (mult_activation): Identity()\n",
       "        (drop): Identity()\n",
       "        (output_linear): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "            (1): QLinear()\n",
       "          )\n",
       "          (1): GLU(dim=-1)\n",
       "        )\n",
       "        (state_quantizer): ActivationQuantizer(self.fake_real='fake', self.num_bits=16, self.dims_to_reduce=[-1, -2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "        (y_recur_quantizer): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "        (y_pre_output_quantizer): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=[-2], self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0): Identity()\n",
       "  )\n",
       "  (dropouts): ModuleList(\n",
       "    (0): Dropout1d(p=0, inplace=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ActivationQuantizer(self.fake_real='fake', self.num_bits=8, self.dims_to_reduce=None, self.percentile=99.999, self.mode='asymmetric', self.zero_point_bits=16)\n",
       "    (1): QLinear()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantize import set_up_quantizers\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up quantizers for the model\n",
    "q_config_fname = r\"../configs/q_config.yaml\"\n",
    "q_config_yaml = read_yaml(q_config_fname)\n",
    "\n",
    "# q_modification = {...} # Optional modification to the quantization config\n",
    "q_modification = None \n",
    "\n",
    "q_config = ConfigParser(q_config_yaml, None, modification=q_modification, save_log=False)\n",
    "\n",
    "\n",
    "q_trainer = set_up_trainer(config)\n",
    "set_up_quantizers(q_trainer, q_config)\n",
    "\n",
    "q_trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating quantized models\n",
    "\n",
    "The default is dynamically quantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 2.390 | Acc: 11.510% (1151/10000): : 20it [00:55,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 11.51, Loss: 2.3902382612228394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.3902382612228394, 'acc': 11.51}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dynamically quantised: default\n",
    "q_trainer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For static quantization, run calibration and call set_static_quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting calibration with 1 batches\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabled quantization for S4BlockRecurrent\n",
      "Disabling quantization for layer_activation\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Disabling quantization for state_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for y_recur_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for y_pre_output_quantizer\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 0\n",
      "Disabled quantization for activation quantizer\n",
      "Disabling quantization for 1\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for state_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for y_recur_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for y_pre_output_quantizer\n",
      "Set up collecting statistics for activation quantizer\n",
      "Starting statistics collection for 0\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for state_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for y_recur_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for y_pre_output_quantizer\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Ending statistics collection for 0\n",
      "Finished collecting statistics for activation quantizer\n",
      "Reset statistics for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for S4BlockRecurrent\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Enabled quantization for activation quantizer\n",
      "Finished calibration\n",
      "Enabled flag for static quantization. Now using static quantization\n",
      "Enabled flag for static quantization. Now using static quantization\n",
      "Enabled flag for static quantization. Now using static quantization\n",
      "Enabled flag for static quantization. Now using static quantization\n",
      "Enabled flag for static quantization. Now using static quantization\n",
      "Enabled flag for static quantization. Now using static quantization\n",
      "Enabled flag for static quantization. Now using static quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST - Batch Idx: (19/20) | Loss: 2.390 | Acc: 11.590% (1159/10000): : 20it [00:17,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Acc: 11.59, Loss: 2.38961843252182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.38961843252182, 'acc': 11.59}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calibration for static quantization\n",
    "q_trainer.calibrate(num_batches=1) # num_batches is the number of batches to use for calibration\n",
    "q_trainer.set_static_quantization()\n",
    "q_trainer.eval()\n",
    "\n",
    "# You can return to dynamic quantization if needed\n",
    "# q_trainer.set_dynamic_quantization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For QAT, simply call train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAT\n",
    "train_log = q_trainer.train()\n",
    "QAT_eval_log = q_trainer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
