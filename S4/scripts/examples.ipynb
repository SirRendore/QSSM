{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..')) # Add parent directory to path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from utils import read_yaml\n",
    "from parse_arguments import ConfigParser\n",
    "from train import set_up_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training FP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fname = r'../configs/S4D_small.yaml' # Path to FP model config file\n",
    "# resume_checkpoint = r\"../log/S4D_small/fp32_16heads/checkpoint/ckpt.pth\" # Path to checkpoint to resume training from\n",
    "resume_checkpoint = None\n",
    "\n",
    "config_yaml = read_yaml(config_fname)\n",
    "# modification = {\"model;type\": 32} # Optional modification to the config\n",
    "modification = None\n",
    "config = ConfigParser(config_yaml, resume_checkpoint, modification=modification, save_log=False) # Set save_log to True to save trained model and logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up FP trainer\n",
    "\n",
    "Hyperparams are set in config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = set_up_trainer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the set_up_quantizers function to perform quantisation. Quantization parameters are set in the qconfig file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantize import set_up_quantizers\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up quantizers for the model\n",
    "q_config_fname = r\"../configs/q_config.yaml\"\n",
    "q_config_yaml = read_yaml(q_config_fname)\n",
    "\n",
    "# q_modification = {...} # Optional modification to the quantization config\n",
    "q_modification = None \n",
    "\n",
    "q_config = ConfigParser(q_config_yaml, None, modification=q_modification, save_log=False)\n",
    "\n",
    "\n",
    "q_trainer = set_up_trainer(config)\n",
    "set_up_quantizers(q_trainer, q_config)\n",
    "\n",
    "q_trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating quantized models\n",
    "\n",
    "The default is dynamically quantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically quantised: default\n",
    "q_trainer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For static quantization, run calibration and call set_static_quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration for static quantization\n",
    "q_trainer.calibrate(num_batches=1) # num_batches is the number of batches to use for calibration\n",
    "q_trainer.set_static_quantization()\n",
    "q_trainer.eval()\n",
    "\n",
    "# You can return to dynamic quantization if needed\n",
    "# q_trainer.set_dynamic_quantization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For QAT, simply call train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAT\n",
    "train_log = q_trainer.train()\n",
    "QAT_eval_log = q_trainer.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QuantisedSSM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
